DETECT-MODERATION-LABELS()                          DETECT-MODERATION-LABELS()



NAME
       detect-moderation-labels -

DESCRIPTION
       Detects unsafe content in a specified JPEG or PNG format image. Use De-
       tectModerationLabels to moderate images depending on your requirements.
       For  example,  you might want to filter images that contain nudity, but
       not images containing suggestive content.

       To filter images, use the labels returned by DetectModerationLabels  to
       determine which types of content are appropriate.

       For  information  about moderation labels, see Detecting Unsafe Content
       in the Amazon Rekognition Developer Guide.

       You pass the input image either as base64-encoded image bytes or  as  a
       reference to an image in an Amazon S3 bucket. If you use the AWS CLI to
       call Amazon Rekognition operations, passing image  bytes  is  not  sup-
       ported. The image must be either a PNG or JPEG formatted file.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            detect-moderation-labels
          [--image <value>]
          [--min-confidence <value>]
          [--human-loop-config <value>]
          [--image-bytes <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --image (structure)
          The  input image as base64-encoded bytes or an S3 object. If you use
          the  AWS  CLI  to  call  Amazon  Rekognition   operations,   passing
          base64-encoded image bytes is not supported.

          If  you  are  using an AWS SDK to call Amazon Rekognition, you might
          not need to base64-encode image bytes passed using the Bytes  field.
          For more information, see Images in the Amazon Rekognition developer
          guide.

          To specify a local file use --image-bytes instead.

          Bytes -> (blob)
              Blob of image bytes up to 5 MBs.

          S3Object -> (structure)
              Identifies an S3 object as the image source.

              Bucket -> (string)
                 Name of the S3 bucket.

              Name -> (string)
                 S3 object key name.

              Version -> (string)
                 If the bucket is versioning enabled, you can specify the  ob-
                 ject version.

       Shorthand Syntax:

          Bytes=blob,S3Object={Bucket=string,Name=string,Version=string}

       JSON Syntax:

          {
            "Bytes": blob,
            "S3Object": {
              "Bucket": "string",
              "Name": "string",
              "Version": "string"
            }
          }

       --min-confidence (float)
          Specifies  the  minimum  confidence  level for the labels to return.
          Amazon Rekognition doesn't return any labels with a confidence level
          lower than this specified value.

          If  you  don't  specify MinConfidence , the operation returns labels
          with confidence values greater than or equal to 50 percent.

       --human-loop-config (structure)
          Sets up  the  configuration  for  human  evaluation,  including  the
          FlowDefinition the image will be sent to.

          HumanLoopName -> (string)
              The name of the human review used for this image. This should be
              kept unique within a region.

          FlowDefinitionArn -> (string)
              The Amazon Resource Name (ARN) of the flow definition.  You  can
              create   a   flow  definition  by  using  the  Amazon  Sagemaker
              CreateFlowDefinition Operation.

          DataAttributes -> (structure)
              Sets attributes of the input data.

              ContentClassifiers -> (list)
                 Sets whether the input image is free of personally  identifi-
                 able information.

                 (string)

       Shorthand Syntax:

          HumanLoopName=string,FlowDefinitionArn=string,DataAttributes={ContentClassifiers=[string,string]}

       JSON Syntax:

          {
            "HumanLoopName": "string",
            "FlowDefinitionArn": "string",
            "DataAttributes": {
              "ContentClassifiers": ["FreeOfPersonallyIdentifiableInformation"|"FreeOfAdultContent", ...]
            }
          }

       --image-bytes (blob)
          The content of the image to be uploaded. To specify the content of a
          local file use the fileb:// prefix. Example: fileb://image.png

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

EXAMPLES
       NOTE:
          To  use  the following examples, you must have the AWS CLI installed
          and configured. See the Getting started guide in the  AWS  CLI  User
          Guide for more information.

          Unless  otherwise  stated,  all  examples  have  unix-like quotation
          rules. These examples will need to be  adapted  to  your  terminal's
          quoting rules. See Using quotation marks with strings in the AWS CLI
          User Guide .

       To detect unsafe content in an image

       The following detect-moderation-labels command detects  unsafe  content
       in the specified image stored in an Amazon S3 bucket.

          aws rekognition detect-moderation-labels \
              --image "S3Object={Bucket=MyImageS3Bucket,Name=gun.jpg}"

       Output:

          {
              "ModerationModelVersion": "3.0",
              "ModerationLabels": [
                  {
                      "Confidence": 97.29618072509766,
                      "ParentName": "Violence",
                      "Name": "Weapon Violence"
                  },
                  {
                      "Confidence": 97.29618072509766,
                      "ParentName": "",
                      "Name": "Violence"
                  }
              ]
          }

       For  more information, see Detecting Unsafe Images in the Amazon Rekog-
       nition Developer Guide.

OUTPUT
       ModerationLabels -> (list)
          Array of detected Moderation labels and the  time,  in  milliseconds
          from the start of the video, they were detected.

          (structure)
              Provides  information  about a single type of inappropriate, un-
              wanted, or offensive content found in an image  or  video.  Each
              type of moderated content has a label within a hierarchical tax-
              onomy. For more information, see Content moderation in the  Ama-
              zon Rekognition Developer Guide.

              Confidence -> (float)
                 Specifies the confidence that Amazon Rekognition has that the
                 label has been correctly identified.

                 If you don't specify the MinConfidence parameter in the  call
                 to DetectModerationLabels , the operation returns labels with
                 a confidence value greater than or equal to 50 percent.

              Name -> (string)
                 The label name for the type of unsafe content detected in the
                 image.

              ParentName -> (string)
                 The name for the parent label. Labels at the top level of the
                 hierarchy have the parent label "" .

       ModerationModelVersion -> (string)
          Version number of the moderation detection model that  was  used  to
          detect unsafe content.

       HumanLoopActivationOutput -> (structure)
          Shows the results of the human in the loop evaluation.

          HumanLoopArn -> (string)
              The Amazon Resource Name (ARN) of the HumanLoop created.

          HumanLoopActivationReasons -> (list)
              Shows if and why human review was needed.

              (string)

          HumanLoopActivationConditionsEvaluationResults -> (string)
              Shows  the result of condition evaluations, including those con-
              ditions which activated a human review.



                                                    DETECT-MODERATION-LABELS()
