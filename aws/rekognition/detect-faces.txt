DETECT-FACES()                                                  DETECT-FACES()



NAME
       detect-faces -

DESCRIPTION
       Detects faces within an image that is provided as input.
          DetectFaces  detects  the  100  largest faces in the image. For each
          face detected, the operation returns face details. These details in-
          clude  a  bounding  box  of  the  face, a confidence value (that the
          bounding box contains a face), and a fixed set of attributes such as
          facial  landmarks (for example, coordinates of eye and mouth), pose,
          presence of facial occlusion, and so on.

       The face-detection algorithm is most effective on  frontal  faces.  For
       non-frontal or obscured faces, the algorithm might not detect the faces
       or might detect faces with lower confidence.

       You pass the input image either as base64-encoded image bytes or  as  a
       reference to an image in an Amazon S3 bucket. If you use the AWS CLI to
       call Amazon Rekognition operations, passing image  bytes  is  not  sup-
       ported. The image must be either a PNG or JPEG formatted file.

       NOTE:
          This  is  a stateless API operation. That is, the operation does not
          persist any data.

       This operation requires permissions to perform the  rekognition:Detect-
       Faces action.

       See also: AWS API Documentation

SYNOPSIS
            detect-faces
          [--image <value>]
          [--attributes <value>]
          [--image-bytes <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --image (structure)
          The  input image as base64-encoded bytes or an S3 object. If you use
          the  AWS  CLI  to  call  Amazon  Rekognition   operations,   passing
          base64-encoded image bytes is not supported.

          If  you  are  using an AWS SDK to call Amazon Rekognition, you might
          not need to base64-encode image bytes passed using the Bytes  field.
          For more information, see Images in the Amazon Rekognition developer
          guide.

          To specify a local file use --image-bytes instead.

          Bytes -> (blob)
              Blob of image bytes up to 5 MBs. Note  that  the  maximum  image
              size you can pass to DetectCustomLabels is 4MB.

          S3Object -> (structure)
              Identifies an S3 object as the image source.

              Bucket -> (string)
                 Name of the S3 bucket.

              Name -> (string)
                 S3 object key name.

              Version -> (string)
                 If  the bucket is versioning enabled, you can specify the ob-
                 ject version.

       Shorthand Syntax:

          Bytes=blob,S3Object={Bucket=string,Name=string,Version=string}

       JSON Syntax:

          {
            "Bytes": blob,
            "S3Object": {
              "Bucket": "string",
              "Name": "string",
              "Version": "string"
            }
          }

       --attributes (list)
          An array of facial attributes you want to  be  returned.  A  DEFAULT
          subset  of  facial  attributes  -  BoundingBox , Confidence , Pose ,
          Quality , and Landmarks - will always be returned. You  can  request
          for  specific  facial attributes (in addition to the default list) -
          by using ["DEFAULT", "FACE_OCCLUDED" ] or just  ["FACE_OCCLUDED"  ].
          You  can  request  for  all facial attributes by using ["ALL"] . Re-
          questing more attributes may increase response time.

          If you provide both, ["ALL", "DEFAULT"] , the service uses a logical
          "AND"  operator  to  determine  which  attributes to return (in this
          case, all attributes).

          (string)

       Syntax:

          "string" "string" ...

          Where valid values are:
            DEFAULT
            ALL
            AGE_RANGE
            BEARD
            EMOTIONS
            EYEGLASSES
            EYES_OPEN
            GENDER
            MOUTH_OPEN
            MUSTACHE
            FACE_OCCLUDED
            SMILE
            SUNGLASSES

       --image-bytes (blob)
          The content of the image to be uploaded. To specify the content of a
          local file use the fileb:// prefix. Example: fileb://image.png

       --cli-input-json  (string) Performs service operation based on the JSON
       string provided. The JSON string follows the format provided by  --gen-
       erate-cli-skeleton.  If  other  arguments  are  provided on the command
       line, the CLI values will override the JSON-provided values. It is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for  --cli-input-json.  If provided with the value output, it validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By default, the AWS CLI uses SSL when communicating with AWS  services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do not sign requests. Credentials will not be loaded if  this  argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The maximum socket read time in seconds. If the value is set to 0,  the
       socket  read  will be blocking and not timeout. The default value is 60
       seconds.

       --cli-connect-timeout (int)

       The maximum socket connect time in seconds. If the value is set  to  0,
       the  socket connect will be blocking and not timeout. The default value
       is 60 seconds.

EXAMPLES
       NOTE:
          To use the following examples, you must have the AWS  CLI  installed
          and  configured.  See  the Getting started guide in the AWS CLI User
          Guide for more information.

          Unless otherwise  stated,  all  examples  have  unix-like  quotation
          rules.  These  examples  will  need to be adapted to your terminal's
          quoting rules. See Using quotation marks with strings in the AWS CLI
          User Guide .

       To detect faces in an image

       The following detect-faces command detects faces in the specified image
       stored in an Amazon S3 bucket.

          aws rekognition detect-faces \
              --image '{"S3Object":{"Bucket":"MyImageS3Bucket","Name":"MyFriend.jpg"}}' \
              --attributes "ALL"

       Output:

          {
              "FaceDetails": [
                  {
                      "Confidence": 100.0,
                      "Eyeglasses": {
                          "Confidence": 98.91107940673828,
                          "Value": false
                      },
                      "Sunglasses": {
                          "Confidence": 99.7966537475586,
                          "Value": false
                      },
                      "Gender": {
                          "Confidence": 99.56611633300781,
                          "Value": "Male"
                      },
                      "Landmarks": [
                          {
                              "Y": 0.26721030473709106,
                              "X": 0.6204193830490112,
                              "Type": "eyeLeft"
                          },
                          {
                              "Y": 0.26831310987472534,
                              "X": 0.6776827573776245,
                              "Type": "eyeRight"
                          },
                          {
                              "Y": 0.3514654338359833,
                              "X": 0.6241428852081299,
                              "Type": "mouthLeft"
                          },
                          {
                              "Y": 0.35258132219314575,
                              "X": 0.6713621020317078,
                              "Type": "mouthRight"
                          },
                          {
                              "Y": 0.3140771687030792,
                              "X": 0.6428444981575012,
                              "Type": "nose"
                          },
                          {
                              "Y": 0.24662546813488007,
                              "X": 0.6001564860343933,
                              "Type": "leftEyeBrowLeft"
                          },
                          {
                              "Y": 0.24326619505882263,
                              "X": 0.6303644776344299,
                              "Type": "leftEyeBrowRight"
                          },
                          {
                              "Y": 0.23818562924861908,
                              "X": 0.6146903038024902,
                              "Type": "leftEyeBrowUp"
                          },
                          {
                              "Y": 0.24373626708984375,
                              "X": 0.6640064716339111,
                              "Type": "rightEyeBrowLeft"
                          },
                          {
                              "Y": 0.24877218902111053,
                              "X": 0.7025929093360901,
                              "Type": "rightEyeBrowRight"
                          },
                          {
                              "Y": 0.23938551545143127,
                              "X": 0.6823262572288513,
                              "Type": "rightEyeBrowUp"
                          },
                          {
                              "Y": 0.265746533870697,
                              "X": 0.6112898588180542,
                              "Type": "leftEyeLeft"
                          },
                          {
                              "Y": 0.2676128149032593,
                              "X": 0.6317071914672852,
                              "Type": "leftEyeRight"
                          },
                          {
                              "Y": 0.262735515832901,
                              "X": 0.6201658248901367,
                              "Type": "leftEyeUp"
                          },
                          {
                              "Y": 0.27025148272514343,
                              "X": 0.6206279993057251,
                              "Type": "leftEyeDown"
                          },
                          {
                              "Y": 0.268223375082016,
                              "X": 0.6658390760421753,
                              "Type": "rightEyeLeft"
                          },
                          {
                              "Y": 0.2672517001628876,
                              "X": 0.687832236289978,
                              "Type": "rightEyeRight"
                          },
                          {
                              "Y": 0.26383838057518005,
                              "X": 0.6769183874130249,
                              "Type": "rightEyeUp"
                          },
                          {
                              "Y": 0.27138751745224,
                              "X": 0.676596462726593,
                              "Type": "rightEyeDown"
                          },
                          {
                              "Y": 0.32283174991607666,
                              "X": 0.6350004076957703,
                              "Type": "noseLeft"
                          },
                          {
                              "Y": 0.3219289481639862,
                              "X": 0.6567046642303467,
                              "Type": "noseRight"
                          },
                          {
                              "Y": 0.3420318365097046,
                              "X": 0.6450609564781189,
                              "Type": "mouthUp"
                          },
                          {
                              "Y": 0.3664324879646301,
                              "X": 0.6455618143081665,
                              "Type": "mouthDown"
                          },
                          {
                              "Y": 0.26721030473709106,
                              "X": 0.6204193830490112,
                              "Type": "leftPupil"
                          },
                          {
                              "Y": 0.26831310987472534,
                              "X": 0.6776827573776245,
                              "Type": "rightPupil"
                          },
                          {
                              "Y": 0.26343393325805664,
                              "X": 0.5946047306060791,
                              "Type": "upperJawlineLeft"
                          },
                          {
                              "Y": 0.3543180525302887,
                              "X": 0.6044883728027344,
                              "Type": "midJawlineLeft"
                          },
                          {
                              "Y": 0.4084877669811249,
                              "X": 0.6477024555206299,
                              "Type": "chinBottom"
                          },
                          {
                              "Y": 0.3562754988670349,
                              "X": 0.707981526851654,
                              "Type": "midJawlineRight"
                          },
                          {
                              "Y": 0.26580461859703064,
                              "X": 0.7234612107276917,
                              "Type": "upperJawlineRight"
                          }
                      ],
                      "Pose": {
                          "Yaw": -3.7351467609405518,
                          "Roll": -0.10309021919965744,
                          "Pitch": 0.8637830018997192
                      },
                      "Emotions": [
                          {
                              "Confidence": 8.74203109741211,
                              "Type": "SURPRISED"
                          },
                          {
                              "Confidence": 2.501944065093994,
                              "Type": "ANGRY"
                          },
                          {
                              "Confidence": 0.7378743290901184,
                              "Type": "DISGUSTED"
                          },
                          {
                              "Confidence": 3.5296201705932617,
                              "Type": "HAPPY"
                          },
                          {
                              "Confidence": 1.7162904739379883,
                              "Type": "SAD"
                          },
                          {
                              "Confidence": 9.518536567687988,
                              "Type": "CONFUSED"
                          },
                          {
                              "Confidence": 0.45474427938461304,
                              "Type": "FEAR"
                          },
                          {
                              "Confidence": 72.79895782470703,
                              "Type": "CALM"
                          }
                      ],
                      "AgeRange": {
                          "High": 48,
                          "Low": 32
                      },
                      "EyesOpen": {
                          "Confidence": 98.93987274169922,
                          "Value": true
                      },
                      "BoundingBox": {
                          "Width": 0.12368916720151901,
                          "Top": 0.16007372736930847,
                          "Left": 0.5901257991790771,
                          "Height": 0.25140416622161865
                      },
                      "Smile": {
                          "Confidence": 93.4493179321289,
                          "Value": false
                      },
                      "MouthOpen": {
                          "Confidence": 90.53053283691406,
                          "Value": false
                      },
                      "Quality": {
                          "Sharpness": 95.51618957519531,
                          "Brightness": 65.29893493652344
                      },
                      "Mustache": {
                          "Confidence": 89.85221099853516,
                          "Value": false
                      },
                      "Beard": {
                          "Confidence": 86.1991195678711,
                          "Value": true
                      }
                  }
              ]
          }

       For more information, see Detecting Faces in an  Image  in  the  Amazon
       Rekognition Developer Guide.

OUTPUT
       FaceDetails -> (list)
          Details of each face found in the image.

          (structure)
              Structure  containing  attributes of the face that the algorithm
              detected.

              A FaceDetail object  contains  either  the  default  facial  at-
              tributes  or  all  facial attributes. The default attributes are
              BoundingBox , Confidence , Landmarks , Pose , and Quality .
                 GetFaceDetection is the only Amazon Rekognition Video  stored
                 video  operation that can return a FaceDetail object with all
                 attributes. To specify which attributes to  return,  use  the
                 FaceAttributes  input parameter for  StartFaceDetection . The
                 following Amazon Rekognition Video operations return only the
                 default  attributes. The corresponding Start operations don't
                 have a FaceAttributes input parameter:

              o GetCelebrityRecognition

              o GetPersonTracking

              o GetFaceSearch

              The Amazon Rekognition Image  DetectFaces and  IndexFaces opera-
              tions  can  return  all  facial attributes. To specify which at-
              tributes to return, use the Attributes input parameter  for  De-
              tectFaces  . For IndexFaces , use the DetectAttributes input pa-
              rameter.

              BoundingBox -> (structure)
                 Bounding box of the face. Default attribute.

                 Width -> (float)
                     Width of the bounding box as a ratio of the overall image
                     width.

                 Height -> (float)
                     Height  of the bounding box as a ratio of the overall im-
                     age height.

                 Left -> (float)
                     Left coordinate of the bounding box as a ratio of overall
                     image width.

                 Top -> (float)
                     Top  coordinate of the bounding box as a ratio of overall
                     image height.

              AgeRange -> (structure)
                 The estimated age range, in years, for the face.  Low  repre-
                 sents  the lowest estimated age and High represents the high-
                 est estimated age.

                 Low -> (integer)
                     The lowest estimated age.

                 High -> (integer)
                     The highest estimated age.

              Smile -> (structure)
                 Indicates whether or not the face is smiling, and the  confi-
                 dence level in the determination.

                 Value -> (boolean)
                     Boolean  value that indicates whether the face is smiling
                     or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Eyeglasses -> (structure)
                 Indicates whether or not the face is wearing eye glasses, and
                 the confidence level in the determination.

                 Value -> (boolean)
                     Boolean  value that indicates whether the face is wearing
                     eye glasses or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Sunglasses -> (structure)
                 Indicates whether or not the face is wearing sunglasses,  and
                 the confidence level in the determination.

                 Value -> (boolean)
                     Boolean  value that indicates whether the face is wearing
                     sunglasses or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Gender -> (structure)
                 The predicted gender of a detected face.

                 Value -> (string)
                     The predicted gender of the face.

                 Confidence -> (float)
                     Level of confidence in the prediction.

              Beard -> (structure)
                 Indicates whether or not the face has a beard, and the confi-
                 dence level in the determination.

                 Value -> (boolean)
                     Boolean  value  that indicates whether the face has beard
                     or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Mustache -> (structure)
                 Indicates whether or not the face has  a  mustache,  and  the
                 confidence level in the determination.

                 Value -> (boolean)
                     Boolean  value  that  indicates whether the face has mus-
                     tache or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              EyesOpen -> (structure)
                 Indicates whether or not the eyes on the face are  open,  and
                 the confidence level in the determination.

                 Value -> (boolean)
                     Boolean value that indicates whether the eyes on the face
                     are open.

                 Confidence -> (float)
                     Level of confidence in the determination.

              MouthOpen -> (structure)
                 Indicates whether or not the mouth on the face is  open,  and
                 the confidence level in the determination.

                 Value -> (boolean)
                     Boolean  value  that  indicates  whether the mouth on the
                     face is open or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Emotions -> (list)
                 The emotions that appear to be expressed on the face, and the
                 confidence level in the determination. The API is only making
                 a determination of the  physical  appearance  of  a  person's
                 face.  It is not a determination of the persons internal emo-
                 tional state and should not be used in such a way. For  exam-
                 ple,  a person pretending to have a sad face might not be sad
                 emotionally.

                 (structure)
                     The emotions that appear to be expressed on the face, and
                     the  confidence  level  in  the determination. The API is
                     only making a determination of the physical appearance of
                     a person's face. It is not a determination of the persons
                     internal emotional state and should not be used in such a
                     way.  For example, a person pretending to have a sad face
                     might not be sad emotionally.

                     Type -> (string)
                        Type of emotion detected.

                     Confidence -> (float)
                        Level of confidence in the determination.

              Landmarks -> (list)
                 Indicates the location of landmarks on the face. Default  at-
                 tribute.

                 (structure)
                     Indicates the location of the landmark on the face.

                     Type -> (string)
                        Type of landmark.

                     X -> (float)
                        The  x-coordinate of the landmark expressed as a ratio
                        of the width of the image. The  x-coordinate  is  mea-
                        sured from the left-side of the image. For example, if
                        the image is 700 pixels wide and the  x-coordinate  of
                        the landmark is at 350 pixels, this value is 0.5.

                     Y -> (float)
                        The  y-coordinate of the landmark expressed as a ratio
                        of the height of the image. The y-coordinate  is  mea-
                        sured  from  the top of the image. For example, if the
                        image height is 200 pixels and the y-coordinate of the
                        landmark is at 50 pixels, this value is 0.25.

              Pose -> (structure)
                 Indicates  the  pose  of the face as determined by its pitch,
                 roll, and yaw. Default attribute.

                 Roll -> (float)
                     Value representing the face rotation on the roll axis.

                 Yaw -> (float)
                     Value representing the face rotation on the yaw axis.

                 Pitch -> (float)
                     Value representing the face rotation on the pitch axis.

              Quality -> (structure)
                 Identifies image brightness and sharpness. Default attribute.

                 Brightness -> (float)
                     Value representing brightness of the  face.  The  service
                     returns  a  value between 0 and 100 (inclusive). A higher
                     value indicates a brighter face image.

                 Sharpness -> (float)
                     Value representing sharpness of the face. The service re-
                     turns  a  value  between  0 and 100 (inclusive). A higher
                     value indicates a sharper face image.

              Confidence -> (float)
                 Confidence level that the bounding box contains a  face  (and
                 not a different object such as a tree). Default attribute.

              FaceOccluded -> (structure)
                     FaceOccluded  should return "true" with a high confidence
                     score if a detected faces eyes, nose, and mouth are  par-
                     tially  captured  or  if  they are covered by masks, dark
                     sunglasses, cell phones, hands, or other objects. FaceOc-
                     cluded should return "false" with a high confidence score
                     if common occurrences that do not impact  face  verifica-
                     tion  are  detected,  such as eye glasses, lightly tinted
                     sunglasses, strands of hair, and others.

                 Value -> (boolean)
                     True if a detected faces eyes, nose, and mouth  are  par-
                     tially  captured  or  if  they are covered by masks, dark
                     sunglasses, cell phones, hands, or other  objects.  False
                     if  common  occurrences that do not impact face verifica-
                     tion are detected, such as eye  glasses,  lightly  tinted
                     sunglasses, strands of hair, and others.

                 Confidence -> (float)
                     The confidence that the service has detected the presence
                     of a face occlusion.

       OrientationCorrection -> (string)
          The value of OrientationCorrection is always null.

          If the input image is in .jpeg format, it might contain exchangeable
          image file format (Exif) metadata that includes the image's orienta-
          tion. Amazon Rekognition uses this orientation information  to  per-
          form  image  correction. The bounding box coordinates are translated
          to represent object locations after the orientation  information  in
          the  Exif  metadata is used to correct the image orientation. Images
          in .png format don't contain Exif metadata.

          Amazon Rekognition doesnt perform image  correction  for  images  in
          .png  format and .jpeg images without orientation information in the
          image Exif metadata. The bounding box coordinates aren't  translated
          and represent the object locations before the image is rotated.



                                                                DETECT-FACES()
