GET-PERSON-TRACKING()                                    GET-PERSON-TRACKING()



NAME
       get-person-tracking -

DESCRIPTION
       Gets  the  path tracking results of a Amazon Rekognition Video analysis
       started by  StartPersonTracking .

       The person path tracking operation is started by a call to StartPerson-
       Tracking  which  returns  a job identifier (JobId ). When the operation
       finishes, Amazon Rekognition Video publishes a completion status to the
       Amazon Simple Notification Service topic registered in the initial call
       to StartPersonTracking .

       To get the results of the person path tracking operation,  first  check
       that  the status value published to the Amazon SNS topic is SUCCEEDED .
       If so, call  GetPersonTracking and pass the  job  identifier  (JobId  )
       from the initial call to StartPersonTracking .
          GetPersonTracking returns an array, Persons , of tracked persons and
          the time(s) their paths were tracked in the video.

       NOTE:
              GetPersonTracking only returns  the  default  facial  attributes
              (BoundingBox  ,  Confidence  , Landmarks , Pose , and Quality ).
              The other facial attributes listed in the  Face  object  of  the
              following response syntax are not returned.

          For  more  information, see FaceDetail in the Amazon Rekognition De-
          veloper Guide.

       By default, the array is sorted by  the  time(s)  a  person's  path  is
       tracked in the video. You can sort by tracked persons by specifying IN-
       DEX for the SortBy input parameter.

       Use the MaxResults parameter to limit the number of items returned.  If
       there  are  more  results  than  specified in MaxResults , the value of
       NextToken in the operation response contains  a  pagination  token  for
       getting  the next set of results. To get the next page of results, call
       GetPersonTracking and populate the NextToken request parameter with the
       token value returned from the previous call to GetPersonTracking .

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            get-person-tracking
          --job-id <value>
          [--max-results <value>]
          [--next-token <value>]
          [--sort-by <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --job-id (string)
          The identifier for a job that tracks persons in a video. You get the
          JobId from a call to StartPersonTracking .

       --max-results (integer)
          Maximum number of results to return per paginated call. The  largest
          value  you  can specify is 1000. If you specify a value greater than
          1000, a maximum of 1000 results is returned. The  default  value  is
          1000.

       --next-token (string)
          If the previous response was incomplete (because there are more per-
          sons to retrieve), Amazon Rekognition Video returns a pagination to-
          ken  in  the response. You can use this pagination token to retrieve
          the next set of persons.

       --sort-by (string)
          Sort to use for elements in the Persons array. Use TIMESTAMP to sort
          array  elements  by the time persons are detected. Use INDEX to sort
          by the tracked persons. If you sort by INDEX ,  the  array  elements
          for each person are sorted by detection confidence. The default sort
          is by TIMESTAMP .

          Possible values:

          o INDEX

          o TIMESTAMP

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

EXAMPLES
       To get the results of a people pathing operation

       The  following  get-person-tracking  command  displays the results of a
       people  pathing  operation  that  you  started  previously  by  calling
       start-person-tracking.

          aws rekognition get-person-tracking  \
              --job-id 1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef

       Output:

          {
              "Persons": [
                  {
                      "Timestamp": 500,
                      "Person": {
                          "BoundingBox": {
                              "Width": 0.4151041805744171,
                              "Top": 0.07870370149612427,
                              "Left": 0.0,
                              "Height": 0.9212962985038757
                          },
                          "Index": 0
                      }
                  },
                  {
                      "Timestamp": 567,
                      "Person": {
                          "BoundingBox": {
                              "Width": 0.4755208194255829,
                              "Top": 0.07777778059244156,
                              "Left": 0.0,
                              "Height": 0.9194444417953491
                          },
                          "Index": 0
                      }
                  }
              ],
              "NextToken": "D/vRIYNyhG79ugdta3f+8cRg9oSRo+HigGOuxRiYpTn0ExnqTi1CJektVAc4HrAXDv25eHYk",
              "JobStatus": "SUCCEEDED",
              "VideoMetadata": {
                  "Format": "QuickTime / MOV",
                  "FrameRate": 29.970617294311523,
                  "Codec": "h264",
                  "DurationMillis": 6806,
                  "FrameHeight": 1080,
                  "FrameWidth": 1920
              }
          }

       For  more information, see People Pathing in the Amazon Rekognition De-
       veloper Guide.

OUTPUT
       JobStatus -> (string)
          The current status of the person tracking job.

       StatusMessage -> (string)
          If the job fails, StatusMessage provides a  descriptive  error  mes-
          sage.

       VideoMetadata -> (structure)
          Information  about  a  video that Amazon Rekognition Video analyzed.
          Videometadata is returned in every page of paginated responses  from
          a Amazon Rekognition Video operation.

          Codec -> (string)
              Type of compression used in the analyzed video.

          DurationMillis -> (long)
              Length of the video in milliseconds.

          Format -> (string)
              Format  of  the analyzed video. Possible values are MP4, MOV and
              AVI.

          FrameRate -> (float)
              Number of frames per second in the video.

          FrameHeight -> (long)
              Vertical pixel dimension of the video.

          FrameWidth -> (long)
              Horizontal pixel dimension of the video.

          ColorRange -> (string)
              A description of the range of luminance values in a  video,  ei-
              ther LIMITED (16 to 235) or FULL (0 to 255).

       NextToken -> (string)
          If  the response is truncated, Amazon Rekognition Video returns this
          token that you can use in the subsequent  request  to  retrieve  the
          next set of persons.

       Persons -> (list)
          An  array of the persons detected in the video and the time(s) their
          path was tracked throughout the video. An array element  will  exist
          for each time a person's path is tracked.

          (structure)
              Details  and  path tracking information for a single time a per-
              son's path is tracked in a video. Amazon Rekognition  operations
              that track people's paths return an array of PersonDetection ob-
              jects with elements for each time a person's path is tracked  in
              a video.

              For more information, see GetPersonTracking in the Amazon Rekog-
              nition Developer Guide.

              Timestamp -> (long)
                 The time, in milliseconds from the start of the  video,  that
                 the person's path was tracked.

              Person -> (structure)
                 Details about a person whose path was tracked in a video.

                 Index -> (long)
                     Identifier for the person detected person within a video.
                     Use to keep track of the person throughout the video. The
                     identifier is not stored by Amazon Rekognition.

                 BoundingBox -> (structure)
                     Bounding box around the detected person.

                     Width -> (float)
                        Width  of  the  bounding box as a ratio of the overall
                        image width.

                     Height -> (float)
                        Height of the bounding box as a ratio of  the  overall
                        image height.

                     Left -> (float)
                        Left  coordinate  of  the  bounding  box as a ratio of
                        overall image width.

                     Top -> (float)
                        Top coordinate of the bounding box as a ratio of over-
                        all image height.

                 Face -> (structure)
                     Face details for the detected person.

                     BoundingBox -> (structure)
                        Bounding box of the face. Default attribute.

                        Width -> (float)
                            Width  of the bounding box as a ratio of the over-
                            all image width.

                        Height -> (float)
                            Height of the bounding box as a ratio of the over-
                            all image height.

                        Left -> (float)
                            Left  coordinate of the bounding box as a ratio of
                            overall image width.

                        Top -> (float)
                            Top coordinate of the bounding box as a  ratio  of
                            overall image height.

                     AgeRange -> (structure)
                        The  estimated  age range, in years, for the face. Low
                        represents the lowest estimated age  and  High  repre-
                        sents the highest estimated age.

                        Low -> (integer)
                            The lowest estimated age.

                        High -> (integer)
                            The highest estimated age.

                     Smile -> (structure)
                        Indicates  whether or not the face is smiling, and the
                        confidence level in the determination.

                        Value -> (boolean)
                            Boolean value that indicates whether the  face  is
                            smiling or not.

                        Confidence -> (float)
                            Level of confidence in the determination.

                     Eyeglasses -> (structure)
                        Indicates  whether  or  not  the  face  is wearing eye
                        glasses, and the confidence level  in  the  determina-
                        tion.

                        Value -> (boolean)
                            Boolean  value  that indicates whether the face is
                            wearing eye glasses or not.

                        Confidence -> (float)
                            Level of confidence in the determination.

                     Sunglasses -> (structure)
                        Indicates whether or not  the  face  is  wearing  sun-
                        glasses,  and  the  confidence level in the determina-
                        tion.

                        Value -> (boolean)
                            Boolean value that indicates whether the  face  is
                            wearing sunglasses or not.

                        Confidence -> (float)
                            Level of confidence in the determination.

                     Gender -> (structure)
                        The predicted gender of a detected face.

                        Value -> (string)
                            The predicted gender of the face.

                        Confidence -> (float)
                            Level of confidence in the prediction.

                     Beard -> (structure)
                        Indicates whether or not the face has a beard, and the
                        confidence level in the determination.

                        Value -> (boolean)
                            Boolean value that indicates whether the face  has
                            beard or not.

                        Confidence -> (float)
                            Level of confidence in the determination.

                     Mustache -> (structure)
                        Indicates  whether or not the face has a mustache, and
                        the confidence level in the determination.

                        Value -> (boolean)
                            Boolean value that indicates whether the face  has
                            mustache or not.

                        Confidence -> (float)
                            Level of confidence in the determination.

                     EyesOpen -> (structure)
                        Indicates  whether  or  not  the  eyes on the face are
                        open, and the confidence level in the determination.

                        Value -> (boolean)
                            Boolean value that indicates whether the  eyes  on
                            the face are open.

                        Confidence -> (float)
                            Level of confidence in the determination.

                     MouthOpen -> (structure)
                        Indicates  whether  or  not  the  mouth on the face is
                        open, and the confidence level in the determination.

                        Value -> (boolean)
                            Boolean value that indicates whether the mouth  on
                            the face is open or not.

                        Confidence -> (float)
                            Level of confidence in the determination.

                     Emotions -> (list)
                        The  emotions that appear to be expressed on the face,
                        and the confidence level in the determination. The API
                        is only making a determination of the physical appear-
                        ance of a person's face. It is not a determination  of
                        the persons internal emotional state and should not be
                        used in such a way. For example, a  person  pretending
                        to have a sad face might not be sad emotionally.

                        (structure)
                            The  emotions  that  appear to be expressed on the
                            face, and the confidence level in  the  determina-
                            tion.  The  API  is only making a determination of
                            the physical appearance of a person's face. It  is
                            not  a  determination of the persons internal emo-
                            tional state and should not be used in such a way.
                            For  example,  a  person  pretending to have a sad
                            face might not be sad emotionally.

                            Type -> (string)
                               Type of emotion detected.

                            Confidence -> (float)
                               Level of confidence in the determination.

                     Landmarks -> (list)
                        Indicates the location of landmarks on the  face.  De-
                        fault attribute.

                        (structure)
                            Indicates  the  location  of  the  landmark on the
                            face.

                            Type -> (string)
                               Type of landmark.

                            X -> (float)
                               The x-coordinate of the landmark expressed as a
                               ratio  of the width of the image. The x-coordi-
                               nate is measured from the left-side of the  im-
                               age.  For  example,  if the image is 700 pixels
                               wide and the x-coordinate of the landmark is at
                               350 pixels, this value is 0.5.

                            Y -> (float)
                               The y-coordinate of the landmark expressed as a
                               ratio of the height of the image. The y-coordi-
                               nate is measured from the top of the image. For
                               example, if the image height is 200 pixels  and
                               the  y-coordinate of the landmark is at 50 pix-
                               els, this value is 0.25.

                     Pose -> (structure)
                        Indicates the pose of the face as  determined  by  its
                        pitch, roll, and yaw. Default attribute.

                        Roll -> (float)
                            Value  representing  the face rotation on the roll
                            axis.

                        Yaw -> (float)
                            Value representing the face rotation  on  the  yaw
                            axis.

                        Pitch -> (float)
                            Value  representing the face rotation on the pitch
                            axis.

                     Quality -> (structure)
                        Identifies image brightness and sharpness. Default at-
                        tribute.

                        Brightness -> (float)
                            Value  representing  brightness  of  the face. The
                            service returns a value between 0 and 100  (inclu-
                            sive).  A  higher  value indicates a brighter face
                            image.

                        Sharpness -> (float)
                            Value representing sharpness of the face. The ser-
                            vice  returns  a  value  between 0 and 100 (inclu-
                            sive). A higher value indicates a sharper face im-
                            age.

                     Confidence -> (float)
                        Confidence level that the bounding box contains a face
                        (and not a different object such as a  tree).  Default
                        attribute.



                                                         GET-PERSON-TRACKING()
