CREATE-DATA-SOURCE-FROM-REDSHIFT()          CREATE-DATA-SOURCE-FROM-REDSHIFT()



NAME
       create-data-source-from-redshift -

DESCRIPTION
       Creates a DataSource from a database hosted on an Amazon Redshift clus-
       ter. A DataSource references data that can be used  to  perform  either
       CreateMLModel , CreateEvaluation , or CreateBatchPrediction operations.
          CreateDataSourceFromRedshift  is  an  asynchronous operation. In re-
          sponse to CreateDataSourceFromRedshift  ,  Amazon  Machine  Learning
          (Amazon  ML)  immediately  returns and sets the DataSource status to
          PENDING . After the DataSource is created and ready for use,  Amazon
          ML  sets the Status parameter to COMPLETED . DataSource in COMPLETED
          or PENDING states can be used to perform only CreateMLModel  ,  Cre-
          ateEvaluation , or CreateBatchPrediction operations.

       If  Amazon ML can't accept the input source, it sets the Status parame-
       ter to FAILED and includes an error message in the Message attribute of
       the GetDataSource operation response.

       The  observations should be contained in the database hosted on an Ama-
       zon Redshift cluster and should be specified by a SelectSqlQuery query.
       Amazon ML executes an Unload command in Amazon Redshift to transfer the
       result set of the SelectSqlQuery query to S3StagingLocation .

       After the DataSource has been created, it's ready for  use  in  evalua-
       tions and batch predictions. If you plan to use the DataSource to train
       an MLModel , the DataSource also requires a recipe. A recipe  describes
       how  each input variable will be used in training an MLModel . Will the
       variable be included or excluded from training? Will  the  variable  be
       manipulated;  for example, will it be combined with another variable or
       will it be split apart into word combinations? The recipe provides  an-
       swers to these questions.

       You  can't  change  an existing datasource, but you can copy and modify
       the settings from an existing Amazon Redshift datasource  to  create  a
       new datasource. To do so, call GetDataSource for an existing datasource
       and copy the values to a CreateDataSource  call.  Change  the  settings
       that you want to change and make sure that all required fields have the
       appropriate values.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            create-data-source-from-redshift
          --data-source-id <value>
          [--data-source-name <value>]
          --data-spec <value>
          --role-arn <value>
          [--compute-statistics | --no-compute-statistics]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --data-source-id (string)
          A user-supplied ID that uniquely identifies the DataSource .

       --data-source-name (string)
          A user-supplied name or description of the DataSource .

       --data-spec (structure)
          The data specification of an Amazon Redshift DataSource :

          o DatabaseInformation -

            o DatabaseName - The name of the Amazon Redshift database.

            o ClusterIdentifier - The unique ID for the Amazon Redshift  clus-
              ter.

          o DatabaseCredentials - The AWS Identity and Access Management (IAM)
            credentials that are used to connect to the Amazon Redshift  data-
            base.

          o SelectSqlQuery  -  The query that is used to retrieve the observa-
            tion data for the Datasource .

          o S3StagingLocation - The Amazon Simple Storage Service (Amazon  S3)
            location for staging Amazon Redshift data. The data retrieved from
            Amazon Redshift using the SelectSqlQuery query is stored  in  this
            location.

          o DataSchemaUri - The Amazon S3 location of the DataSchema .

          o DataSchema  -  A  JSON string representing the schema. This is not
            required if DataSchemaUri is specified.

          o DataRearrangement - A JSON string that  represents  the  splitting
            and  rearrangement  requirements  for  the  DataSource  . Sample -
            "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"

          DatabaseInformation -> (structure)
              Describes the DatabaseName and ClusterIdentifier for  an  Amazon
              Redshift DataSource .

              DatabaseName -> (string)
                 The name of a database hosted on an Amazon Redshift cluster.

              ClusterIdentifier -> (string)
                 The ID of an Amazon Redshift cluster.

          SelectSqlQuery -> (string)
              Describes  the  SQL Query to execute on an Amazon Redshift data-
              base for an Amazon Redshift DataSource .

          DatabaseCredentials -> (structure)
              Describes AWS Identity and Access Management  (IAM)  credentials
              that are used connect to the Amazon Redshift database.

              Username -> (string)
                 A  username  to  be  used  by Amazon Machine Learning (Amazon
                 ML)to connect to a database on an  Amazon  Redshift  cluster.
                 The  username  should  have sufficient permissions to execute
                 the RedshiftSelectSqlQuery  query.  The  username  should  be
                 valid for an Amazon Redshift USER .

              Password -> (string)
                 A  password  to be used by Amazon ML to connect to a database
                 on an Amazon Redshift cluster. The password should have  suf-
                 ficient   permissions  to  execute  a  RedshiftSelectSqlQuery
                 query. The password should be valid for  an  Amazon  Redshift
                 USER .

          S3StagingLocation -> (string)
              Describes  an  Amazon S3 location to store the result set of the
              SelectSqlQuery query.

          DataRearrangement -> (string)
              A JSON string that represents the  splitting  and  rearrangement
              processing to be applied to a DataSource . If the DataRearrange-
              ment parameter is not provided, all of the input data is used to
              create the Datasource .

              There  are multiple parameters that control what data is used to
              create a datasource:

              o

                **
                percentBegin **   Use percentBegin to indicate  the  beginning
                of the range of the data used to create the Datasource. If you
                do not include percentBegin and percentEnd  ,  Amazon  ML  in-
                cludes all of the data when creating the datasource.

              o

                **
                percentEnd  **    Use  percentEnd  to  indicate the end of the
                range of the data used to create the Datasource. If you do not
                include  percentBegin  and percentEnd , Amazon ML includes all
                of the data when creating the datasource.

              o

                **
                complement **   The complement parameter instructs  Amazon  ML
                to  use the data that is not included in the range of percent-
                Begin to percentEnd to create a datasource. The complement pa-
                rameter  is  useful  if you need to create complementary data-
                sources for training and evaluation. To create a complementary
                datasource,  use  the  same  values  for percentBegin and per-
                centEnd , along with the complement  parameter.  For  example,
                the  following  two datasources do not share any data, and can
                be used to train and evaluate a model.  The  first  datasource
                has  25 percent of the data, and the second one has 75 percent
                of the data. Datasource  for  evaluation:  {"splitting":{"per-
                centBegin":0,  "percentEnd":25}}    Datasource  for  training:
                {"splitting":{"percentBegin":0,   "percentEnd":25,    "comple-
                ment":"true"}}

              o

                **
                strategy  **    To  change how Amazon ML splits the data for a
                datasource, use the strategy parameter. The default value  for
                the  strategy parameter is sequential , meaning that Amazon ML
                takes all of the data records  between  the  percentBegin  and
                percentEnd  parameters  for  the datasource, in the order that
                the records appear  in  the  input  data.  The  following  two
                DataRearrangement  lines  are examples of sequentially ordered
                training and evaluation datasources:  Datasource  for  evalua-
                tion:    {"splitting":{"percentBegin":70,    "percentEnd":100,
                "strategy":"sequential"}}   Datasource for training:  {"split-
                ting":{"percentBegin":70,   "percentEnd":100,  "strategy":"se-
                quential", "complement":"true"}}   To randomly split the input
                data  into  the  proportions indicated by the percentBegin and
                percentEnd parameters, set the strategy  parameter  to  random
                and  provide  a  string that is used as the seed value for the
                random data splitting (for example, you can use the S3 path to
                your data as the random seed string). If you choose the random
                split  strategy,  Amazon  ML  assigns  each  row  of  data   a
                pseudo-random  number  between 0 and 100, and then selects the
                rows that have an assigned  number  between  percentBegin  and
                percentEnd . Pseudo-random numbers are assigned using both the
                input seed string value and the byte  offset  as  a  seed,  so
                changing  the  data results in a different split. Any existing
                ordering is preserved. The random splitting  strategy  ensures
                that  variables  in  the training and evaluation data are dis-
                tributed similarly. It is useful in the cases where the  input
                data  may  have  an implicit sort order, which would otherwise
                result  in  training  and  evaluation  datasources  containing
                non-similar  data records. The following two DataRearrangement
                lines are examples of non-sequentially  ordered  training  and
                evaluation  datasources:  Datasource  for evaluation: {"split-
                ting":{"percentBegin":70,  "percentEnd":100,  "strategy":"ran-
                dom", "randomSeed"="s3://my_s3_path/bucket/file.csv"}}   Data-
                source for  training:  {"splitting":{"percentBegin":70,  "per-
                centEnd":100,           "strategy":"random",          "random-
                Seed"="s3://my_s3_path/bucket/file.csv", "complement":"true"}}

          DataSchema -> (string)
              A JSON string that represents the schema for an Amazon  Redshift
              DataSource  . The DataSchema defines the structure of the obser-
              vation data in the data file(s) referenced in the DataSource .

              A DataSchema is not required if you specify a DataSchemaUri .

              Define your DataSchema as  a  series  of  key-value  pairs.  at-
              tributes  and  excludedVariableNames  have an array of key-value
              pairs for their value. Use the following format to  define  your
              DataSchema .

              { "version": "1.0",

              "recordAnnotationFieldName": "F1",

              "recordWeightFieldName": "F2",

              "targetFieldName": "F3",

              "dataFormat": "CSV",

              "dataFileContainsHeader": true,

              "attributes": [

              { "fieldName": "F1", "fieldType": "TEXT" }, { "fieldName": "F2",
              "fieldType": "NUMERIC"  },  {  "fieldName":  "F3",  "fieldType":
              "CATEGORICAL"  }, { "fieldName": "F4", "fieldType": "NUMERIC" },
              { "fieldName": "F5", "fieldType":  "CATEGORICAL"  },  {  "field-
              Name": "F6", "fieldType": "TEXT" }, { "fieldName": "F7", "field-
              Type": "WEIGHTED_INT_SEQUENCE" }, { "fieldName":  "F8",  "field-
              Type": "WEIGHTED_STRING_SEQUENCE" } ],

              "excludedVariableNames": [ "F6" ] }

          DataSchemaUri -> (string)
              Describes  the schema location for an Amazon Redshift DataSource
              .

       Shorthand Syntax:

          DatabaseInformation={DatabaseName=string,ClusterIdentifier=string},SelectSqlQuery=string,DatabaseCredentials={Username=string,Password=string},S3StagingLocation=string,DataRearrangement=string,DataSchema=string,DataSchemaUri=string

       JSON Syntax:

          {
            "DatabaseInformation": {
              "DatabaseName": "string",
              "ClusterIdentifier": "string"
            },
            "SelectSqlQuery": "string",
            "DatabaseCredentials": {
              "Username": "string",
              "Password": "string"
            },
            "S3StagingLocation": "string",
            "DataRearrangement": "string",
            "DataSchema": "string",
            "DataSchemaUri": "string"
          }

       --role-arn (string)
          A fully specified role Amazon Resource Name (ARN). Amazon ML assumes
          the role on behalf of the user to create the following:

          o A  security group to allow Amazon ML to execute the SelectSqlQuery
            query on an Amazon Redshift cluster

          o An Amazon S3 bucket policy to grant Amazon ML  read/write  permis-
            sions on the S3StagingLocation

       --compute-statistics | --no-compute-statistics (boolean)
          The  compute statistics for a DataSource . The statistics are gener-
          ated from the observation data referenced by a DataSource  .  Amazon
          ML  uses the statistics internally during MLModel training. This pa-
          rameter must be set to true if the DataSource needs to be  used  for
          MLModel training.

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       DataSourceId -> (string)
          A  user-supplied  ID  that  uniquely identifies the datasource. This
          value should be identical to the value of the  DataSourceID  in  the
          request.



                                            CREATE-DATA-SOURCE-FROM-REDSHIFT()
