START-TRANSCRIPTION-JOB()                            START-TRANSCRIPTION-JOB()



NAME
       start-transcription-job -

DESCRIPTION
       Starts an asynchronous job to transcribe speech to text.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            start-transcription-job
          --transcription-job-name <value>
          [--language-code <value>]
          [--media-sample-rate-hertz <value>]
          [--media-format <value>]
          --media <value>
          [--output-bucket-name <value>]
          [--output-key <value>]
          [--output-encryption-kms-key-id <value>]
          [--kms-encryption-context <value>]
          [--settings <value>]
          [--model-settings <value>]
          [--job-execution-settings <value>]
          [--content-redaction <value>]
          [--identify-language | --no-identify-language]
          [--language-options <value>]
          [--subtitles <value>]
          [--tags <value>]
          [--language-id-settings <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --transcription-job-name (string)
          The  name  of  the  job.  You can't use the strings ". " or ".. " by
          themselves as the job name. The name must also be unique  within  an
          Amazon  Web  Services  account. If you try to create a transcription
          job with the same name as a previous transcription job,  you  get  a
          ConflictException error.

       --language-code (string)
          The language code for the language used in the input media file.

          To  transcribe  speech in Modern Standard Arabic (ar-SA), your audio
          or video file must be encoded at a  sample  rate  of  16,000  Hz  or
          higher.

          Possible values:

          o af-ZA

          o ar-AE

          o ar-SA

          o cy-GB

          o da-DK

          o de-CH

          o de-DE

          o en-AB

          o en-AU

          o en-GB

          o en-IE

          o en-IN

          o en-US

          o en-WL

          o es-ES

          o es-US

          o fa-IR

          o fr-CA

          o fr-FR

          o ga-IE

          o gd-GB

          o he-IL

          o hi-IN

          o id-ID

          o it-IT

          o ja-JP

          o ko-KR

          o ms-MY

          o nl-NL

          o pt-BR

          o pt-PT

          o ru-RU

          o ta-IN

          o te-IN

          o tr-TR

          o zh-CN

          o zh-TW

          o th-TH

          o en-ZA

          o en-NZ

       --media-sample-rate-hertz (integer)
          The  sample  rate,  in  Hertz, of the audio track in the input media
          file.

          If you do not specify the media sample rate, Amazon  Transcribe  de-
          termines  the  sample  rate. If you specify the sample rate, it must
          match the sample rate detected by Amazon Transcribe. In most  cases,
          you should leave the MediaSampleRateHertz field blank and let Amazon
          Transcribe determine the sample rate.

       --media-format (string)
          The format of the input media file.

          Possible values:

          o mp3

          o mp4

          o wav

          o flac

          o ogg

          o amr

          o webm

       --media (structure)
          An object that describes the input media for a transcription job.

          MediaFileUri -> (string)
              The S3 object location of the input media file. The URI must  be
              in the same region as the API endpoint that you are calling. The
              general form is:
                 s3://DOC-EXAMPLE-BUCKET/keyprefix/objectkey

              For example:
                 s3://DOC-EXAMPLE-BUCKET/example.flac

                 s3://DOC-EXAMPLE-BUCKET/mediafiles/example.flac

              For more information about S3 object names, see Object  Keys  in
              the Amazon S3 Developer Guide .

          RedactedMediaFileUri -> (string)
              The S3 object location for your redacted output media file. This
              is only supported for call analytics jobs.

       Shorthand Syntax:

          MediaFileUri=string,RedactedMediaFileUri=string

       JSON Syntax:

          {
            "MediaFileUri": "string",
            "RedactedMediaFileUri": "string"
          }

       --output-bucket-name (string)
          The location where the transcription is stored.

          If you set the OutputBucketName , Amazon Transcribe puts  the  tran-
          script  in the specified S3 bucket. When you call the  GetTranscrip-
          tionJob operation, the operation returns this location in the  Tran-
          scriptFileUri  field.  If you enable content redaction, the redacted
          transcript appears in RedactedTranscriptFileUri . If you enable con-
          tent  redaction  and choose to output an unredacted transcript, that
          transcript's location still appears in the TranscriptFileUri  .  The
          S3  bucket must have permissions that allow Amazon Transcribe to put
          files in the bucket. For more information, see Permissions  Required
          for IAM User Roles .

          You  can specify an Amazon Web Services Key Management Service (KMS)
          key to encrypt the output of your transcription using the  OutputEn-
          cryptionKMSKeyId  parameter.  If you don't specify a KMS key, Amazon
          Transcribe uses the default Amazon S3 key for server-side encryption
          of transcripts that are placed in your S3 bucket.

          If  you don't set the OutputBucketName , Amazon Transcribe generates
          a pre-signed URL, a shareable URL that  provides  secure  access  to
          your  transcription,  and returns it in the TranscriptFileUri field.
          Use this URL to download the transcription.

       --output-key (string)
          You can specify a location in an Amazon S3 bucket to store the  out-
          put of your transcription job.

          If  you  don't  specify  an output key, Amazon Transcribe stores the
          output of your transcription job in the Amazon S3 bucket you  speci-
          fied.    By    default,   the   object   key   is   "your-transcrip-
          tion-job-name.json".

          You can use output keys to specify the Amazon  S3  prefix  and  file
          name of the transcription output. For example, specifying the Amazon
          S3 prefix, "folder1/folder2/", as an output key would  lead  to  the
          output     being    stored    as    "folder1/folder2/your-transcrip-
          tion-job-name.json". If you specify "my-other-job-name.json" as  the
          output  key,  the object key is changed to "my-other-job-name.json".
          You can use an output key to change both the  prefix  and  the  file
          name, for example "folder/my-other-job-name.json".

          If  you specify an output key, you must also specify an S3 bucket in
          the OutputBucketName parameter.

       --output-encryption-kms-key-id (string)
          The Amazon Resource Name (ARN) of the Amazon Web Services  Key  Man-
          agement  Service  (KMS)  key used to encrypt the output of the tran-
          scription job. The user calling the StartTranscriptionJob  operation
          must have permission to use the specified KMS key.

          You  can  use  either  of the following to identify a KMS key in the
          current account:

          o KMS Key ID: "1234abcd-12ab-34cd-56ef-1234567890ab"

          o KMS Key Alias: "alias/ExampleAlias"

          You can use either of the following to identify a  KMS  key  in  the
          current account or another account:

          o Amazon  Resource  Name (ARN) of a KMS Key: "arn:aws:kms:region:ac-
            count ID:key/1234abcd-12ab-34cd-56ef-1234567890ab"

          o ARN of a KMS Key Alias: "arn:aws:kms:region:account-ID:alias/Exam-
            pleAlias"

          If you don't specify an encryption key, the output of the transcrip-
          tion job is encrypted with the default Amazon S3 key (SSE-S3).

          If you specify a KMS key to encrypt your output, you must also spec-
          ify an output location in the OutputBucketName parameter.

       --kms-encryption-context (map)
          A map of plain text, non-secret key:value pairs, known as encryption
          context pairs, that provide an added  layer  of  security  for  your
          data.

          key -> (string)

          value -> (string)

       Shorthand Syntax:

          KeyName1=string,KeyName2=string

       JSON Syntax:

          {"string": "string"
            ...}

       --settings (structure)
          A  Settings  object that provides optional settings for a transcrip-
          tion job.

          VocabularyName -> (string)
              The name of a vocabulary to use when processing  the  transcrip-
              tion job.

          ShowSpeakerLabels -> (boolean)
              Determines  whether  the transcription job uses speaker recogni-
              tion to identify different speakers in the input audio.  Speaker
              recognition labels individual speakers in the audio file. If you
              set the ShowSpeakerLabels field to true, you must also  set  the
              maximum number of speaker labels MaxSpeakerLabels field.

              You  can't  set both ShowSpeakerLabels and ChannelIdentification
              in the same request. If you set both,  your  request  returns  a
              BadRequestException .

          MaxSpeakerLabels -> (integer)
              The  maximum  number of speakers to identify in the input audio.
              If there are more speakers in the audio than this number, multi-
              ple  speakers are identified as a single speaker. If you specify
              the MaxSpeakerLabels field, you must set  the  ShowSpeakerLabels
              field to true.

          ChannelIdentification -> (boolean)
              Instructs  Amazon Transcribe to process each audio channel sepa-
              rately and then merge the transcription output of  each  channel
              into a single transcription.

              Amazon Transcribe also produces a transcription of each item de-
              tected on an audio channel, including the  start  time  and  end
              time  of the item and alternative transcriptions of the item in-
              cluding the confidence that Amazon Transcribe has in  the  tran-
              scription.

              You  can't  set both ShowSpeakerLabels and ChannelIdentification
              in the same request. If you set both,  your  request  returns  a
              BadRequestException .

          ShowAlternatives -> (boolean)
              Determines  whether the transcription contains alternative tran-
              scriptions. If you set the ShowAlternatives field to  true,  you
              must  also  set  the maximum number of alternatives to return in
              the MaxAlternatives field.

          MaxAlternatives -> (integer)
              The number of alternative transcriptions that the service should
              return.  If  you specify the MaxAlternatives field, you must set
              the ShowAlternatives field to true.

          VocabularyFilterName -> (string)
              The name of the vocabulary filter to use when  transcribing  the
              audio.  The  filter that you specify must have the same language
              code as the transcription job.

          VocabularyFilterMethod -> (string)
              Set to mask to remove filtered text from the transcript and  re-
              place it with three asterisks ("
              **

              *
              ")  as  placeholder  text. Set to remove to remove filtered text
              from the transcript without using placeholder text. Set  to  tag
              to  mark  the  word in the transcription output that matches the
              vocabulary filter. When you set the filter method to tag  ,  the
              words matching your vocabulary filter are not masked or removed.

              System Message: WARNING/2 (<string>:, line 519)
                     Inline strong start-string without end-string.

              System Message: WARNING/2 (<string>:, line 519)
                     Inline emphasis start-string without end-string.

       Shorthand Syntax:

          VocabularyName=string,ShowSpeakerLabels=boolean,MaxSpeakerLabels=integer,ChannelIdentification=boolean,ShowAlternatives=boolean,MaxAlternatives=integer,VocabularyFilterName=string,VocabularyFilterMethod=string

       JSON Syntax:

          {
            "VocabularyName": "string",
            "ShowSpeakerLabels": true|false,
            "MaxSpeakerLabels": integer,
            "ChannelIdentification": true|false,
            "ShowAlternatives": true|false,
            "MaxAlternatives": integer,
            "VocabularyFilterName": "string",
            "VocabularyFilterMethod": "remove"|"mask"|"tag"
          }

       --model-settings (structure)
          Choose  the custom language model you use for your transcription job
          in this parameter.

          LanguageModelName -> (string)
              The name of your custom language model.

       Shorthand Syntax:

          LanguageModelName=string

       JSON Syntax:

          {
            "LanguageModelName": "string"
          }

       --job-execution-settings (structure)
          Provides information about how a transcription job is executed.  Use
          this  field to indicate that the job can be queued for deferred exe-
          cution if the concurrency limit is reached and there  are  no  slots
          available to immediately run the job.

          AllowDeferredExecution -> (boolean)
              Indicates  whether  a  job should be queued by Amazon Transcribe
              when the concurrent execution limit is exceeded.  When  the  Al-
              lowDeferredExecution field is true, jobs are queued and executed
              when the number of executing jobs falls below the concurrent ex-
              ecution  limit. If the field is false, Amazon Transcribe returns
              a LimitExceededException exception.

              Note that job queuing is enabled by default for  call  analytics
              jobs.

              If  you specify the AllowDeferredExecution field, you must spec-
              ify the DataAccessRoleArn field.

          DataAccessRoleArn -> (string)
              The Amazon Resource Name (ARN), in the  form  arn:partition:ser-
              vice:region:account-id:resource-type/resource-id  ,  of  a  role
              that has access to the S3 bucket that contains the input  files.
              Amazon  Transcribe assumes this role to read queued media files.
              If you have specified an output S3 bucket for the  transcription
              results,  this  role  should have access to the output bucket as
              well.

              If you specify the AllowDeferredExecution field, you must  spec-
              ify the DataAccessRoleArn field.

       Shorthand Syntax:

          AllowDeferredExecution=boolean,DataAccessRoleArn=string

       JSON Syntax:

          {
            "AllowDeferredExecution": true|false,
            "DataAccessRoleArn": "string"
          }

       --content-redaction (structure)
          An  object  that  contains the request parameters for content redac-
          tion.

          RedactionType -> (string)
              Request parameter that defines the entities to be redacted.  The
              only accepted value is PII .

          RedactionOutput -> (string)
              The  output  transcript  file  stored  in  either the default S3
              bucket or in a bucket you specify.

              When you choose redacted  Amazon  Transcribe  outputs  only  the
              redacted transcript.

              When  you  choose redacted_and_unredacted Amazon Transcribe out-
              puts both the redacted and unredacted transcripts.

          PiiEntityTypes -> (list)
              The types of personally identifiable information (PII) you  want
              to redact in your transcript.

              (string)

       Shorthand Syntax:

          RedactionType=string,RedactionOutput=string,PiiEntityTypes=string,string

       JSON Syntax:

          {
            "RedactionType": "PII",
            "RedactionOutput": "redacted"|"redacted_and_unredacted",
            "PiiEntityTypes": ["BANK_ACCOUNT_NUMBER"|"BANK_ROUTING"|"CREDIT_DEBIT_NUMBER"|"CREDIT_DEBIT_CVV"|"CREDIT_DEBIT_EXPIRY"|"PIN"|"EMAIL"|"ADDRESS"|"NAME"|"PHONE"|"SSN"|"ALL", ...]
          }

       --identify-language | --no-identify-language (boolean)
          Set  this field to true to enable automatic language identification.
          Automatic language identification is disabled by  default.  You  re-
          ceive  a  BadRequestException  error if you enter a value for a Lan-
          guageCode .

       --language-options (list)
          An object containing a list of languages that might  be  present  in
          your  collection  of  audio files. Automatic language identification
          chooses a language that best matches  the  source  audio  from  that
          list.

          To  transcribe  speech in Modern Standard Arabic (ar-SA), your audio
          or video file must be encoded at a  sample  rate  of  16,000  Hz  or
          higher.

          (string)

       Syntax:

          "string" "string" ...

          Where valid values are:
            af-ZA
            ar-AE
            ar-SA
            cy-GB
            da-DK
            de-CH
            de-DE
            en-AB
            en-AU
            en-GB
            en-IE
            en-IN
            en-US
            en-WL
            es-ES
            es-US
            fa-IR
            fr-CA
            fr-FR
            ga-IE
            gd-GB
            he-IL
            hi-IN
            id-ID
            it-IT
            ja-JP
            ko-KR
            ms-MY
            nl-NL
            pt-BR
            pt-PT
            ru-RU
            ta-IN
            te-IN
            tr-TR
            zh-CN
            zh-TW
            th-TH
            en-ZA
            en-NZ

       --subtitles (structure)
          Add subtitles to your batch transcription job.

          Formats -> (list)
              Specify the output format for your subtitle file.

              (string)

       Shorthand Syntax:

          Formats=string,string

       JSON Syntax:

          {
            "Formats": ["vtt"|"srt", ...]
          }

       --tags (list)
          Add tags to an Amazon Transcribe transcription job.

          (structure)
              A key:value pair that adds metadata to a resource used by Amazon
              Transcribe. For example, a tag with the key:value  pair  Depart-
              ment:Sales  might  be added to a resource to indicate its use by
              your organization's sales department.

              Key -> (string)
                 The first part of a key:value pair that forms a  tag  associ-
                 ated  with  a given resource. For example, in the tag Depart-
                 ment:Sales, the key is 'Department'.

              Value -> (string)
                 The second part of a key:value pair that forms a tag  associ-
                 ated  with  a given resource. For example, in the tag Depart-
                 ment:Sales, the value is 'Sales'.

       Shorthand Syntax:

          Key=string,Value=string ...

       JSON Syntax:

          [
            {
              "Key": "string",
              "Value": "string"
            }
            ...
          ]

       --language-id-settings (map)
          The language identification settings associated with your transcrip-
          tion  job. These settings include VocabularyName , VocabularyFilter-
          Name , and LanguageModelName .

          key -> (string)

          value -> (structure)
              Language-specific settings that can be specified  when  language
              identification is enabled.

              VocabularyName -> (string)
                 The  name  of  the vocabulary you want to use when processing
                 your transcription job. The vocabulary you specify must  have
                 the same language codes as the transcription job; if the lan-
                 guages don't match, the vocabulary isn't applied.

              VocabularyFilterName -> (string)
                 The name of the vocabulary filter you want to use when  tran-
                 scribing  your  audio.  The  filter you specify must have the
                 same language codes as the transcription  job;  if  the  lan-
                 guages don't match, the vocabulary filter isn't be applied.

              LanguageModelName -> (string)
                 The  name  of  the  language model you want to use when tran-
                 scribing your audio. The model you specify must have the same
                 language  codes  as  the  transcription job; if the languages
                 don't match, the language model isn't be applied.

       Shorthand Syntax:

            KeyName1=VocabularyName=string,VocabularyFilterName=string,LanguageModelName=string,KeyName2=VocabularyName=string,VocabularyFilterName=string,LanguageModelName=string

          Where valid key names are:
            af-ZA
            ar-AE
            ar-SA
            cy-GB
            da-DK
            de-CH
            de-DE
            en-AB
            en-AU
            en-GB
            en-IE
            en-IN
            en-US
            en-WL
            es-ES
            es-US
            fa-IR
            fr-CA
            fr-FR
            ga-IE
            gd-GB
            he-IL
            hi-IN
            id-ID
            it-IT
            ja-JP
            ko-KR
            ms-MY
            nl-NL
            pt-BR
            pt-PT
            ru-RU
            ta-IN
            te-IN
            tr-TR
            zh-CN
            zh-TW
            th-TH
            en-ZA
            en-NZ

       JSON Syntax:

          {"af-ZA"|"ar-AE"|"ar-SA"|"cy-GB"|"da-DK"|"de-CH"|"de-DE"|"en-AB"|"en-AU"|"en-GB"|"en-IE"|"en-IN"|"en-US"|"en-WL"|"es-ES"|"es-US"|"fa-IR"|"fr-CA"|"fr-FR"|"ga-IE"|"gd-GB"|"he-IL"|"hi-IN"|"id-ID"|"it-IT"|"ja-JP"|"ko-KR"|"ms-MY"|"nl-NL"|"pt-BR"|"pt-PT"|"ru-RU"|"ta-IN"|"te-IN"|"tr-TR"|"zh-CN"|"zh-TW"|"th-TH"|"en-ZA"|"en-NZ": {
                "VocabularyName": "string",
                "VocabularyFilterName": "string",
                "LanguageModelName": "string"
              }
            ...}

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

EXAMPLES
       Example 1: To transcribe an audio file

       The  following  start-transcription-job  example transcribes your audio
       file.

          aws transcribe start-transcription-job \
              --cli-input-json file://myfile.json

       Contents of myfile.json:

          {
              "TranscriptionJobName": "cli-simple-transcription-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              }
          }

       For more information, see Getting Started (AWS Command Line  Interface)
       in the Amazon Transcribe Developer Guide.

       Example 2: To transcribe a multi-channel audio file

       The   following   start-transcription-job   example   transcribes  your
       multi-channel audio file.

          aws transcribe start-transcription-job \
              --cli-input-json file://mysecondfile.json

       Contents of mysecondfile.json:

          {
              "TranscriptionJobName": "cli-channelid-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "ChannelIdentification":true
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-channelid-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-17T16:07:56.817000+00:00",
                  "CreationTime": "2020-09-17T16:07:56.784000+00:00",
                  "Settings": {
                      "ChannelIdentification": true
                  }
              }
          }

       For more information, see Transcribing Multi-Channel Audio in the  Ama-
       zon Transcribe Developer Guide.

       Example  3:  To  transcribe  an  audio  file and identify the different
       speakers

       The following start-transcription-job example  transcribes  your  audio
       file and identifies the speakers in the transcription output.

          aws transcribe start-transcription-job \
              --cli-input-json file://mythirdfile.json

       Contents of mythirdfile.json:

          {
              "TranscriptionJobName": "cli-speakerid-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
              "ShowSpeakerLabels": true,
              "MaxSpeakerLabels": 2
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-speakerid-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-17T16:22:59.696000+00:00",
                  "CreationTime": "2020-09-17T16:22:59.676000+00:00",
                  "Settings": {
                      "ShowSpeakerLabels": true,
                      "MaxSpeakerLabels": 2
                  }
              }
          }

       For more information, see Identifying Speakers in the Amazon Transcribe
       Developer Guide.

       Example 4: To transcribe an audio file and mask any unwanted  words  in
       the transcription output

       The  following  start-transcription-job  example transcribes your audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://myfourthfile.json

       Contents of myfourthfile.json:

          {
              "TranscriptionJobName": "cli-filter-mask-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                    "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "VocabularyFilterName": "your-vocabulary-filter",
                  "VocabularyFilterMethod": "mask"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-filter-mask-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
                  "StartTime": "2020-09-18T16:36:18.568000+00:00",
                  "CreationTime": "2020-09-18T16:36:18.547000+00:00",
                  "Settings": {
                      "VocabularyFilterName": "your-vocabulary-filter",
                      "VocabularyFilterMethod": "mask"
                  }
              }
          }

       For  more information, see Filtering Transcriptions in the Amazon Tran-
       scribe Developer Guide.

       Example 5: To transcribe an audio file and remove any unwanted words in
       the transcription output

       The  following  start-transcription-job  example transcribes your audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://myfifthfile.json

       Contents of myfifthfile.json:

          {
              "TranscriptionJobName": "cli-filter-remove-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "VocabularyFilterName": "your-vocabulary-filter",
                  "VocabularyFilterMethod": "remove"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-filter-remove-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-18T16:36:18.568000+00:00",
                  "CreationTime": "2020-09-18T16:36:18.547000+00:00",
                  "Settings": {
                      "VocabularyFilterName": "your-vocabulary-filter",
                      "VocabularyFilterMethod": "remove"
                  }
              }
          }

       For  more information, see Filtering Transcriptions in the Amazon Tran-
       scribe Developer Guide.

       Example 6: To transcribe an audio file with increased accuracy using  a
       custom vocabulary

       The  following  start-transcription-job  example transcribes your audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://mysixthfile.json

       Contents of mysixthfile.json:

          {
              "TranscriptionJobName": "cli-vocab-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "VocabularyName": "your-vocabulary"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-vocab-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-18T16:36:18.568000+00:00",
                  "CreationTime": "2020-09-18T16:36:18.547000+00:00",
                  "Settings": {
                      "VocabularyName": "your-vocabulary"
                  }
              }
          }

       For  more information, see Filtering Transcriptions in the Amazon Tran-
       scribe Developer Guide.

       Example 7: To identify the language of an audio file and transcribe it

       The following start-transcription-job example  transcribes  your  audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://myseventhfile.json

       Contents of myseventhfile.json:

          {
              "TranscriptionJobName": "cli-identify-language-transcription-job",
              "IdentifyLanguage": true,
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-identify-language-transcription-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-18T22:27:23.970000+00:00",
                  "CreationTime": "2020-09-18T22:27:23.948000+00:00",
                  "IdentifyLanguage": true
              }
          }

       For more information, see Identifying the Language in the Amazon  Tran-
       scribe Developer Guide.

       Example 8: To transcribe an audio file with personally identifiable in-
       formation redacted

       The following start-transcription-job example  transcribes  your  audio
       file  and  redacts any personally identifiable information in the tran-
       scription output.

          aws transcribe start-transcription-job \
              --cli-input-json file://myeighthfile.json

       Contents of myeigthfile.json:

          {
              "TranscriptionJobName": "cli-redaction-job",
              "LanguageCode": "language-code",
              "Media": {
                  "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
              },
              "ContentRedaction": {
                  "RedactionOutput":"redacted",
                  "RedactionType":"PII"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-redaction-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "language-code",
                  "Media": {
                      "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
                  "StartTime": "2020-09-25T23:49:13.195000+00:00",
                  "CreationTime": "2020-09-25T23:49:13.176000+00:00",
                  "ContentRedaction": {
                      "RedactionType": "PII",
                      "RedactionOutput": "redacted"
                  }
              }
          }

       For more information, see Automatic Content  Redaction  in  the  Amazon
       Transcribe Developer Guide.

       Example 9: To generate a transcript with personally identifiable infor-
       mation (PII) redacted and an unredacted transcript

       The following start-transcription-job example generates  two  transcrp-
       tions of your audio file, one with the personally identifiable informa-
       tion redacted, and the other without any redactions.

          aws transcribe start-transcription-job \
              --cli-input-json file://myninthfile.json

       Contents of myninthfile.json:

          {
              "TranscriptionJobName": "cli-redaction-job-with-unredacted-transcript",
              "LanguageCode": "language-code",
              "Media": {
                    "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
              "ContentRedaction": {
                  "RedactionOutput":"redacted_and_unredacted",
                  "RedactionType":"PII"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-redaction-job-with-unredacted-transcript",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "language-code",
                  "Media": {
                      "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
                  "StartTime": "2020-09-25T23:59:47.677000+00:00",
                  "CreationTime": "2020-09-25T23:59:47.653000+00:00",
                  "ContentRedaction": {
                      "RedactionType": "PII",
                      "RedactionOutput": "redacted_and_unredacted"
                  }
              }
          }

       For more information, see Automatic Content  Redaction  in  the  Amazon
       Transcribe Developer Guide.

       Example 10: To use a custom language model you've previously created to
       transcribe an audio file.

       The following start-transcription-job example  transcribes  your  audio
       file with a custom language model you've previously created.

          aws transcribe start-transcription-job \
              --cli-input-json file://mytenthfile.json

       Contents of mytenthfile.json:

          {
              "TranscriptionJobName": "cli-clm-2-job-1",
              "LanguageCode": "language-code",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/your-audio-file.file-extension"
              },
              "ModelSettings": {
                  "LanguageModelName":"cli-clm-2"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-clm-2-job-1",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "language-code",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/your-audio-file.file-extension"
                  },
                  "StartTime": "2020-09-28T17:56:01.835000+00:00",
                  "CreationTime": "2020-09-28T17:56:01.801000+00:00",
                  "ModelSettings": {
                      "LanguageModelName": "cli-clm-2"
                  }
              }
          }

       For more information, see Improving Domain-Specific Transcription Accu-
       racy with Custom Language Models in  the  Amazon  Transcribe  Developer
       Guide.

OUTPUT
       TranscriptionJob -> (structure)
          An object containing details of the asynchronous transcription job.

          TranscriptionJobName -> (string)
              The name of the transcription job.

          TranscriptionJobStatus -> (string)
              The status of the transcription job.

          LanguageCode -> (string)
              The language code for the input speech.

          MediaSampleRateHertz -> (integer)
              The  sample rate, in Hertz (Hz), of the audio track in the input
              media file.

          MediaFormat -> (string)
              The format of the input media file.

          Media -> (structure)
              An object that describes the input media for  the  transcription
              job.

              MediaFileUri -> (string)
                 The  S3 object location of the input media file. The URI must
                 be in the same region as the API endpoint that you are  call-
                 ing. The general form is:
                     s3://DOC-EXAMPLE-BUCKET/keyprefix/objectkey

                 For example:
                     s3://DOC-EXAMPLE-BUCKET/example.flac

                     s3://DOC-EXAMPLE-BUCKET/mediafiles/example.flac

                 For  more  information about S3 object names, see Object Keys
                 in the Amazon S3 Developer Guide .

              RedactedMediaFileUri -> (string)
                 The S3 object location for your redacted output  media  file.
                 This is only supported for call analytics jobs.

          Transcript -> (structure)
              An object that describes the output of the transcription job.

              TranscriptFileUri -> (string)
                 The S3 object location of the transcript.

                 Use this URI to access the transcript. If you specified an S3
                 bucket in the OutputBucketName field  when  you  created  the
                 job,  this  is  the URI of that bucket. If you chose to store
                 the transcript in Amazon Transcribe, this is a shareable  URL
                 that provides secure access to that location.

              RedactedTranscriptFileUri -> (string)
                 The S3 object location of the redacted transcript.

                 Use this URI to access the redacted transcript. If you speci-
                 fied an S3 bucket in the OutputBucketName field when you cre-
                 ated the job, this is the URI of that bucket. If you chose to
                 store the transcript in Amazon Transcribe, this is  a  share-
                 able URL that provides secure access to that location.

          StartTime -> (timestamp)
              A timestamp that shows when the job started processing.

          CreationTime -> (timestamp)
              A timestamp that shows when the job was created.

          CompletionTime -> (timestamp)
              A timestamp that shows when the job completed.

          FailureReason -> (string)
              If  the TranscriptionJobStatus field is FAILED , this field con-
              tains information about why the job failed.

              The FailureReason field can contain one of the following values:

              o Unsupported media format - The media format specified  in  the
                MediaFormat field of the request isn't valid. See the descrip-
                tion of the MediaFormat field for a list of valid values.

              o The media format provided does not match  the  detected  media
                format  - The media format of the audio file doesn't match the
                format specified in the  MediaFormat  field  in  the  request.
                Check  the  media format of your media file and make sure that
                the two values match.

              o Invalid sample rate for audio file - The sample rate specified
                in  the  MediaSampleRateHertz  of the request isn't valid. The
                sample rate must be between 8,000 and 48,000 Hertz.

              o The sample rate provided does not match  the  detected  sample
                rate  -  The  sample  rate in the audio file doesn't match the
                sample rate specified in the MediaSampleRateHertz field in the
                request.  Check  the  sample  rate of your media file and make
                sure that the two values match.

              o Invalid file size: file size too large - The size of your  au-
                dio  file  is  larger  than Amazon Transcribe can process. For
                more information, see Limits in the Amazon  Transcribe  Devel-
                oper Guide .

              o Invalid  number  of  channels:  number of channels too large -
                Your audio contains more channels than  Amazon  Transcribe  is
                configured  to  process.  To  request additional channels, see
                Amazon Transcribe Limits in the Amazon  Web  Services  General
                Reference .

          Settings -> (structure)
              Optional  settings for the transcription job. Use these settings
              to turn on speaker recognition, to set  the  maximum  number  of
              speakers  that  should be identified and to specify a custom vo-
              cabulary to use when processing the transcription job.

              VocabularyName -> (string)
                 The name of a vocabulary to use  when  processing  the  tran-
                 scription job.

              ShowSpeakerLabels -> (boolean)
                 Determines  whether the transcription job uses speaker recog-
                 nition to identify different speakers  in  the  input  audio.
                 Speaker  recognition  labels individual speakers in the audio
                 file. If you set the ShowSpeakerLabels  field  to  true,  you
                 must  also set the maximum number of speaker labels MaxSpeak-
                 erLabels field.

                 You can't set both ShowSpeakerLabels  and  ChannelIdentifica-
                 tion  in  the same request. If you set both, your request re-
                 turns a BadRequestException .

              MaxSpeakerLabels -> (integer)
                 The maximum number of speakers to identify in the  input  au-
                 dio.  If  there are more speakers in the audio than this num-
                 ber, multiple speakers are identified as a single speaker. If
                 you  specify  the  MaxSpeakerLabels  field,  you must set the
                 ShowSpeakerLabels field to true.

              ChannelIdentification -> (boolean)
                 Instructs Amazon Transcribe to  process  each  audio  channel
                 separately  and  then  merge the transcription output of each
                 channel into a single transcription.

                 Amazon Transcribe also produces a transcription of each  item
                 detected  on  an  audio channel, including the start time and
                 end time of the item and alternative  transcriptions  of  the
                 item  including  the confidence that Amazon Transcribe has in
                 the transcription.

                 You can't set both ShowSpeakerLabels  and  ChannelIdentifica-
                 tion  in  the same request. If you set both, your request re-
                 turns a BadRequestException .

              ShowAlternatives -> (boolean)
                 Determines whether  the  transcription  contains  alternative
                 transcriptions.  If  you  set  the  ShowAlternatives field to
                 true, you must also set the maximum number of alternatives to
                 return in the MaxAlternatives field.

              MaxAlternatives -> (integer)
                 The  number  of  alternative  transcriptions that the service
                 should return. If you specify the MaxAlternatives field,  you
                 must set the ShowAlternatives field to true.

              VocabularyFilterName -> (string)
                 The  name  of  the vocabulary filter to use when transcribing
                 the audio. The filter that you specify  must  have  the  same
                 language code as the transcription job.

              VocabularyFilterMethod -> (string)
                 Set  to  mask to remove filtered text from the transcript and
                 replace it with three asterisks ("
                 **

                 *
                 ") as placeholder text. Set to remove to remove filtered text
                 from  the  transcript  without using placeholder text. Set to
                 tag to mark the word in the transcription output that matches
                 the  vocabulary filter. When you set the filter method to tag
                 , the words matching your vocabulary filter are not masked or
                 removed.

                 System Message: WARNING/2 (<string>:, line 1702)
                        Inline strong start-string without end-string.

                 System Message: WARNING/2 (<string>:, line 1702)
                        Inline emphasis start-string without end-string.

          ModelSettings -> (structure)
              An object containing the details of your custom language model.

              LanguageModelName -> (string)
                 The name of your custom language model.

          JobExecutionSettings -> (structure)
              Provides information about how a transcription job is executed.

              AllowDeferredExecution -> (boolean)
                 Indicates whether a job should be queued by Amazon Transcribe
                 when the concurrent execution limit is exceeded. When the Al-
                 lowDeferredExecution  field is true, jobs are queued and exe-
                 cuted when the number of executing jobs falls below the  con-
                 current  execution limit. If the field is false, Amazon Tran-
                 scribe returns a LimitExceededException exception.

                 Note that job queuing is enabled by default for call  analyt-
                 ics jobs.

                 If  you  specify  the  AllowDeferredExecution field, you must
                 specify the DataAccessRoleArn field.

              DataAccessRoleArn -> (string)
                 The Amazon  Resource  Name  (ARN),  in  the  form  arn:parti-
                 tion:service:region:account-id:resource-type/resource-id , of
                 a role that has access to the S3 bucket that contains the in-
                 put files. Amazon Transcribe assumes this role to read queued
                 media files. If you have specified an output  S3  bucket  for
                 the  transcription  results,  this role should have access to
                 the output bucket as well.

                 If you specify the  AllowDeferredExecution  field,  you  must
                 specify the DataAccessRoleArn field.

          ContentRedaction -> (structure)
              An  object  that  describes  content  redaction settings for the
              transcription job.

              RedactionType -> (string)
                 Request parameter that defines the entities to  be  redacted.
                 The only accepted value is PII .

              RedactionOutput -> (string)
                 The  output  transcript  file stored in either the default S3
                 bucket or in a bucket you specify.

                 When you choose redacted Amazon Transcribe outputs  only  the
                 redacted transcript.

                 When  you  choose  redacted_and_unredacted  Amazon Transcribe
                 outputs both the redacted and unredacted transcripts.

              PiiEntityTypes -> (list)
                 The types of personally identifiable  information  (PII)  you
                 want to redact in your transcript.

                 (string)

          IdentifyLanguage -> (boolean)
              A  value that shows if automatic language identification was en-
              abled for a transcription job.

          LanguageOptions -> (list)
              An object that shows the optional array  of  languages  inputted
              for  transcription  jobs  with automatic language identification
              enabled.

              (string)

          IdentifiedLanguageScore -> (float)
              A value between zero and one that Amazon Transcribe assigned  to
              the language that it identified in the source audio. Larger val-
              ues indicate that Amazon Transcribe has higher confidence in the
              language it identified.

          Tags -> (list)
              A key:value pair assigned to a given transcription job.

              (structure)
                 A  key:value  pair  that  adds metadata to a resource used by
                 Amazon Transcribe. For example, a tag with the key:value pair
                 Department:Sales might be added to a resource to indicate its
                 use by your organization's sales department.

                 Key -> (string)
                     The first part of a key:value pair that forms a tag asso-
                     ciated with a given resource. For example, in the tag De-
                     partment:Sales, the key is 'Department'.

                 Value -> (string)
                     The second part of a key:value pair that forms a tag  as-
                     sociated  with  a given resource. For example, in the tag
                     Department:Sales, the value is 'Sales'.

          Subtitles -> (structure)
              Generate subtitles for your batch transcription job.

              Formats -> (list)
                 Specify the output format for your subtitle file; if you  se-
                 lect  both  SRT  and VTT formats, two output files are gener-
                 ated.

                 (string)

              SubtitleFileUris -> (list)
                 Contains the output location for your subtitle file. This lo-
                 cation must be an S3 bucket.

                 (string)

          LanguageIdSettings -> (map)
              Language-specific  settings  that can be specified when language
              identification is enabled for your transcription job. These set-
              tings  include  VocabularyName , VocabularyFilterName , and Lan-
              guageModelName .

              key -> (string)

              value -> (structure)
                 Language-specific settings that can be  specified  when  lan-
                 guage identification is enabled.

                 VocabularyName -> (string)
                     The  name of the vocabulary you want to use when process-
                     ing your transcription job. The  vocabulary  you  specify
                     must  have  the  same language codes as the transcription
                     job; if the languages don't match, the  vocabulary  isn't
                     applied.

                 VocabularyFilterName -> (string)
                     The  name  of  the vocabulary filter you want to use when
                     transcribing your audio. The filter you specify must have
                     the  same language codes as the transcription job; if the
                     languages don't match, the vocabulary filter isn't be ap-
                     plied.

                 LanguageModelName -> (string)
                     The name of the language model you want to use when tran-
                     scribing your audio. The model you specify must have  the
                     same language codes as the transcription job; if the lan-
                     guages don't match, the language model isn't be applied.



                                                     START-TRANSCRIPTION-JOB()
