LIST-INFERENCE-EXECUTIONS()                        LIST-INFERENCE-EXECUTIONS()



NAME
       list-inference-executions -

DESCRIPTION
       Lists  all  inference executions that have been performed by the speci-
       fied inference scheduler.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            list-inference-executions
          [--next-token <value>]
          [--max-results <value>]
          --inference-scheduler-name <value>
          [--data-start-time-after <value>]
          [--data-end-time-before <value>]
          [--status <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --next-token (string)
          An opaque pagination token indicating where to continue the  listing
          of inference executions.

       --max-results (integer)
          Specifies the maximum number of inference executions to list.

       --inference-scheduler-name (string)
          The  name  of  the  inference  scheduler for the inference execution
          listed.

       --data-start-time-after (timestamp)
          The time reference in the  inferenced  dataset  after  which  Amazon
          Lookout for Equipment started the inference execution.

       --data-end-time-before (timestamp)
          The  time  reference  in  the inferenced dataset before which Amazon
          Lookout for Equipment stopped the inference execution.

       --status (string)
          The status of the inference execution.

          Possible values:

          o IN_PROGRESS

          o SUCCESS

          o FAILED

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       NextToken -> (string)
          An  opaque pagination token indicating where to continue the listing
          of inference executions.

       InferenceExecutionSummaries -> (list)
          Provides an array of information about the individual inference exe-
          cutions returned from the ListInferenceExecutions operation, includ-
          ing model used, inference scheduler, data configuration, and so on.

          (structure)
              Contains information about the specific inference execution, in-
              cluding  input and output data configuration, inference schedul-
              ing information, status, and so on.

              ModelName -> (string)
                 The name of the ML model being used for the inference  execu-
                 tion.

              ModelArn -> (string)
                 The  Amazon  Resource Name (ARN) of the ML model used for the
                 inference execution.

              InferenceSchedulerName -> (string)
                 The name of the inference scheduler being used for the infer-
                 ence execution.

              InferenceSchedulerArn -> (string)
                 The Amazon Resource Name (ARN) of the inference scheduler be-
                 ing used for the inference execution.

              ScheduledStartTime -> (timestamp)
                 Indicates the start time at which the inference scheduler be-
                 gan the specific inference execution.

              DataStartTime -> (timestamp)
                 Indicates  the time reference in the dataset at which the in-
                 ference execution began.

              DataEndTime -> (timestamp)
                 Indicates the time reference in the dataset at which the  in-
                 ference execution stopped.

              DataInputConfiguration -> (structure)
                 Specifies  configuration  information  for the input data for
                 the inference scheduler,  including  delimiter,  format,  and
                 dataset location.

                 S3InputConfiguration -> (structure)
                     Specifies  configuration  information  for the input data
                     for the inference, including S3 location of input data..

                     Bucket -> (string)
                        The bucket containing the input dataset for the infer-
                        ence.

                     Prefix -> (string)
                        The  prefix  for the S3 bucket used for the input data
                        for the inference.

                 InputTimeZoneOffset -> (string)
                     Indicates the  difference  between  your  time  zone  and
                     Greenwich Mean Time (GMT).

                 InferenceInputNameConfiguration -> (structure)
                     Specifies  configuration  information  for the input data
                     for the inference, including timestamp format and  delim-
                     iter.

                     TimestampFormat -> (string)
                        The  format  of  the timestamp, whether Epoch time, or
                        standard, with or without hyphens (-).

                     ComponentTimestampDelimiter -> (string)
                        Indicates the delimiter character used  between  items
                        in the data.

              DataOutputConfiguration -> (structure)
                 Specifies  configuration  information  for the output results
                 from for the inference execution, including the output S3 lo-
                 cation.

                 S3OutputConfiguration -> (structure)
                     Specifies  configuration  information  for the output re-
                     sults from for the inference, output S3 location.

                     Bucket -> (string)
                        The bucket containing the output results from the  in-
                        ference

                     Prefix -> (string)
                        The  prefix  for the S3 bucket used for the output re-
                        sults from the inference.

                 KmsKeyId -> (string)
                     The ID number for the AWS KMS key used to encrypt the in-
                     ference output.

              CustomerResultObject -> (structure)
                 Bucket -> (string)
                     The name of the specific S3 bucket.

                 Key -> (string)
                     The  AWS  Key Management Service (AWS KMS) key being used
                     to encrypt the S3 object. Without this key, data  in  the
                     bucket is not accessible.

              Status -> (string)
                 Indicates the status of the inference execution.

              FailedReason -> (string)
                 Specifies  the reason for failure when an inference execution
                 has failed.



                                                   LIST-INFERENCE-EXECUTIONS()
