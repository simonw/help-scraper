CREATE-INFERENCE-SCHEDULER()                      CREATE-INFERENCE-SCHEDULER()



NAME
       create-inference-scheduler -

DESCRIPTION
       Creates  a scheduled inference. Scheduling an inference is setting up a
       continuous real-time inference plan to analyze  new  measurement  data.
       When setting up the schedule, you provide an S3 bucket location for the
       input data, assign it a delimiter between separate entries in the data,
       set  an  offset delay if desired, and set the frequency of inferencing.
       You must also provide an S3 bucket location for the output data.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            create-inference-scheduler
          --model-name <value>
          --inference-scheduler-name <value>
          [--data-delay-offset-in-minutes <value>]
          --data-upload-frequency <value>
          --data-input-configuration <value>
          --data-output-configuration <value>
          --role-arn <value>
          [--server-side-kms-key-id <value>]
          [--client-token <value>]
          [--tags <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --model-name (string)
          The name of the previously trained ML model being used to create the
          inference scheduler.

       --inference-scheduler-name (string)
          The name of the inference scheduler being created.

       --data-delay-offset-in-minutes (long)
          A  period of time (in minutes) by which inference on the data is de-
          layed after the data starts. For instance, if you select  an  offset
          delay time of five minutes, inference will not begin on the data un-
          til the first data measurement after the five minute mark. For exam-
          ple,  if five minutes is selected, the inference scheduler will wake
          up at the configured frequency with the additional five minute delay
          time  to  check the customer S3 bucket. The customer can upload data
          at the same frequency and they don't need to stop  and  restart  the
          scheduler when uploading new data.

       --data-upload-frequency (string)
          How  often  data  is  uploaded to the source S3 bucket for the input
          data. The value chosen is the length of time between  data  uploads.
          For  instance, if you select 5 minutes, Amazon Lookout for Equipment
          will upload the real-time data to the source  bucket  once  every  5
          minutes. This frequency also determines how often Amazon Lookout for
          Equipment starts a scheduled inference on your data. In  this  exam-
          ple, it starts once every 5 minutes.

          Possible values:

          o PT5M

          o PT10M

          o PT15M

          o PT30M

          o PT1H

       --data-input-configuration (structure)
          Specifies  configuration  information for the input data for the in-
          ference scheduler, including delimiter, format,  and  dataset  loca-
          tion.

          S3InputConfiguration -> (structure)
              Specifies  configuration  information for the input data for the
              inference, including Amazon S3 location of input data.

              Bucket -> (string)
                 The bucket containing the input dataset for the inference.

              Prefix -> (string)
                 The prefix for the S3 bucket used for the input data for  the
                 inference.

          InputTimeZoneOffset -> (string)
              Indicates  the difference between your time zone and Coordinated
              Universal Time (UTC).

          InferenceInputNameConfiguration -> (structure)
              Specifies configuration information for the input data  for  the
              inference, including timestamp format and delimiter.

              TimestampFormat -> (string)
                 The format of the timestamp, whether Epoch time, or standard,
                 with or without hyphens (-).

              ComponentTimestampDelimiter -> (string)
                 Indicates the delimiter character used between items  in  the
                 data.

       Shorthand Syntax:

          S3InputConfiguration={Bucket=string,Prefix=string},InputTimeZoneOffset=string,InferenceInputNameConfiguration={TimestampFormat=string,ComponentTimestampDelimiter=string}

       JSON Syntax:

          {
            "S3InputConfiguration": {
              "Bucket": "string",
              "Prefix": "string"
            },
            "InputTimeZoneOffset": "string",
            "InferenceInputNameConfiguration": {
              "TimestampFormat": "string",
              "ComponentTimestampDelimiter": "string"
            }
          }

       --data-output-configuration (structure)
          Specifies  configuration  information for the output results for the
          inference scheduler, including the S3 location for the output.

          S3OutputConfiguration -> (structure)
              Specifies configuration information for the output results  from
              for the inference, output S3 location.

              Bucket -> (string)
                 The bucket containing the output results from the inference

              Prefix -> (string)
                 The prefix for the S3 bucket used for the output results from
                 the inference.

          KmsKeyId -> (string)
              The ID number for the AWS KMS key used to encrypt the  inference
              output.

       Shorthand Syntax:

          S3OutputConfiguration={Bucket=string,Prefix=string},KmsKeyId=string

       JSON Syntax:

          {
            "S3OutputConfiguration": {
              "Bucket": "string",
              "Prefix": "string"
            },
            "KmsKeyId": "string"
          }

       --role-arn (string)
          The  Amazon  Resource Name (ARN) of a role with permission to access
          the data source being used for the inference.

       --server-side-kms-key-id (string)
          Provides the identifier of the KMS key  used  to  encrypt  inference
          scheduler data by Amazon Lookout for Equipment.

       --client-token (string)
          A  unique  identifier  for the request. If you do not set the client
          request token, Amazon Lookout for Equipment generates one.

       --tags (list)
          Any tags associated with the inference scheduler.

          (structure)
              A tag is a key-value pair that can be added  to  a  resource  as
              metadata.

              Key -> (string)
                 The key for the specified tag.

              Value -> (string)
                 The value for the specified tag.

       Shorthand Syntax:

          Key=string,Value=string ...

       JSON Syntax:

          [
            {
              "Key": "string",
              "Value": "string"
            }
            ...
          ]

       --cli-input-json  (string) Performs service operation based on the JSON
       string provided. The JSON string follows the format provided by  --gen-
       erate-cli-skeleton.  If  other  arguments  are  provided on the command
       line, the CLI values will override the JSON-provided values. It is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for  --cli-input-json.  If provided with the value output, it validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       InferenceSchedulerArn -> (string)
          The Amazon Resource Name (ARN) of the inference scheduler being cre-
          ated.

       InferenceSchedulerName -> (string)
          The name of inference scheduler being created.

       Status -> (string)
          Indicates the status of the CreateInferenceScheduler operation.



                                                  CREATE-INFERENCE-SCHEDULER()
