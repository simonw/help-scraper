CREATE-TRANSFORM-JOB()                                  CREATE-TRANSFORM-JOB()



NAME
       create-transform-job -

DESCRIPTION
       Starts a transform job. A transform job uses a trained model to get in-
       ferences on a dataset and saves these results to an Amazon S3  location
       that you specify.

       To  perform  batch  transformations, you create a transform job and use
       the data that you have readily available.

       In the request body, you provide the following:

       o TransformJobName - Identifies the transform job.  The  name  must  be
         unique within an Amazon Web Services Region in an Amazon Web Services
         account.

       o ModelName - Identifies the model to use. ModelName must be  the  name
         of an existing Amazon SageMaker model in the same Amazon Web Services
         Region and Amazon Web Services account. For information on creating a
         model, see CreateModel .

       o TransformInput - Describes the dataset to be transformed and the Ama-
         zon S3 location where it is stored.

       o TransformOutput - Identifies the Amazon S3 location  where  you  want
         Amazon SageMaker to save the results from the transform job.

       o TransformResources  -  Identifies  the  ML  compute instances for the
         transform job.

       For more information about how batch transformation  works,  see  Batch
       Transform .

       See also: AWS API Documentation

SYNOPSIS
            create-transform-job
          --transform-job-name <value>
          --model-name <value>
          [--max-concurrent-transforms <value>]
          [--model-client-config <value>]
          [--max-payload-in-mb <value>]
          [--batch-strategy <value>]
          [--environment <value>]
          --transform-input <value>
          --transform-output <value>
          [--data-capture-config <value>]
          --transform-resources <value>
          [--data-processing <value>]
          [--tags <value>]
          [--experiment-config <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --transform-job-name (string)
          The  name  of  the  transform job. The name must be unique within an
          Amazon Web Services Region in an Amazon Web Services account.

       --model-name (string)
          The name of the model that you want to use for  the  transform  job.
          ModelName  must  be  the  name of an existing Amazon SageMaker model
          within an Amazon Web Services Region in an Amazon Web  Services  ac-
          count.

       --max-concurrent-transforms (integer)
          The maximum number of parallel requests that can be sent to each in-
          stance in a transform job. If MaxConcurrentTransforms is set to 0 or
          left  unset,  Amazon SageMaker checks the optional execution-parame-
          ters to determine the settings for your chosen algorithm. If the ex-
          ecution-parameters endpoint is not enabled, the default value is 1 .
          For more information on  execution-parameters,  see  How  Containers
          Serve  Requests  .  For built-in algorithms, you don't need to set a
          value for MaxConcurrentTransforms .

       --model-client-config (structure)
          Configures the timeout and maximum number of retries for  processing
          a transform job invocation.

          InvocationsTimeoutInSeconds -> (integer)
              The  timeout value in seconds for an invocation request. The de-
              fault value is 600.

          InvocationsMaxRetries -> (integer)
              The maximum number of retries when invocation requests are fail-
              ing. The default value is 3.

       Shorthand Syntax:

          InvocationsTimeoutInSeconds=integer,InvocationsMaxRetries=integer

       JSON Syntax:

          {
            "InvocationsTimeoutInSeconds": integer,
            "InvocationsMaxRetries": integer
          }

       --max-payload-in-mb (integer)
          The  maximum  allowed  size  of the payload, in MB. A payload is the
          data portion of a record (without metadata). The  value  in  MaxPay-
          loadInMB  must  be  greater  than, or equal to, the size of a single
          record. To estimate the size of a record in MB, divide the  size  of
          your  dataset  by  the number of records. To ensure that the records
          fit within the maximum payload size, we recommend using  a  slightly
          larger value. The default value is 6 MB.

          The  value  of  MaxPayloadInMB cannot be greater than 100 MB. If you
          specify the MaxConcurrentTransforms parameter, the value of (MaxCon-
          currentTransforms * MaxPayloadInMB) also cannot exceed 100 MB.

          For cases where the payload might be arbitrarily large and is trans-
          mitted using HTTP chunked encoding, set the value to 0 .  This  fea-
          ture works only in supported algorithms. Currently, Amazon SageMaker
          built-in algorithms do not support HTTP chunked encoding.

       --batch-strategy (string)
          Specifies the number of records to include in a  mini-batch  for  an
          HTTP  inference  request.  A  record  is a single unit of input data
          that inference can be made on. For example, a single line in  a  CSV
          file is a record.

          To enable the batch strategy, you must set the SplitType property to
          Line , RecordIO , or TFRecord .

          To use only one record when making an HTTP invocation request  to  a
          container, set BatchStrategy to SingleRecord and SplitType to Line .

          To fit as many records in a mini-batch as can fit within the MaxPay-
          loadInMB limit, set BatchStrategy to MultiRecord  and  SplitType  to
          Line .

          Possible values:

          o MultiRecord

          o SingleRecord

       --environment (map)
          The  environment variables to set in the Docker container. Don't in-
          clude any sensitive data in your environment variables.  We  support
          up to 16 key and values entries in the map.

          key -> (string)

          value -> (string)

       Shorthand Syntax:

          KeyName1=string,KeyName2=string

       JSON Syntax:

          {"string": "string"
            ...}

       --transform-input (structure)
          Describes  the  input  source and the way the transform job consumes
          it.

          DataSource -> (structure)
              Describes the location of the channel data, which is, the S3 lo-
              cation of the input data that the model can consume.

              S3DataSource -> (structure)
                 The  S3 location of the data source that is associated with a
                 channel.

                 S3DataType -> (string)
                     If you choose S3Prefix , S3Uri identifies a key name pre-
                     fix. Amazon SageMaker uses all objects with the specified
                     key name prefix for batch transform.

                     If you choose ManifestFile , S3Uri identifies  an  object
                     that  is a manifest file containing a list of object keys
                     that you want Amazon SageMaker to use  for  batch  trans-
                     form.

                     The  following  values  are  compatible:  ManifestFile  ,
                     S3Prefix

                     The following value is not compatible: AugmentedManifest-
                     File

                 S3Uri -> (string)
                     Depending  on  the  value  specified for the S3DataType ,
                     identifies either a key name prefix or  a  manifest.  For
                     example:

                     o A  key  name  prefix might look like this: s3://bucket-
                       name/exampleprefix/ .

                     o A manifest might look like this:  s3://bucketname/exam-
                       ple.manifest    The manifest is an S3 object which is a
                       JSON file with the  following  format:    [  {"prefix":
                       "s3://customer_bucket/some/prefix/"},            "rela-
                       tive/path/to/custdata-1",          "relative/path/cust-
                       data-2",      ...      "relative/path/custdata-N"     ]
                       The preceding  JSON  matches  the  following  S3Uris  :
                       s3://customer_bucket/some/prefix/relative/path/to/cust-
                       data-1           s3://customer_bucket/some/prefix/rela-
                       tive/path/custdata-2            ...           s3://cus-
                       tomer_bucket/some/prefix/relative/path/custdata-N   The
                       complete set of S3Uris in this manifest constitutes the
                       input data for the channel for this datasource. The ob-
                       ject that each S3Uris points to must be readable by the
                       IAM role that Amazon SageMaker uses to perform tasks on
                       your behalf.

          ContentType -> (string)
              The  multipurpose  internet  mail  extension  (MIME) type of the
              data. Amazon SageMaker uses the MIME type with each http call to
              transfer data to the transform job.

          CompressionType -> (string)
              If  your  transform  data is compressed, specify the compression
              type. Amazon SageMaker automatically decompresses the  data  for
              the transform job accordingly. The default value is None .

          SplitType -> (string)
              The  method  to use to split the transform job's data files into
              smaller batches. Splitting is necessary when the total  size  of
              each  object  is  too  large to fit in a single request. You can
              also use data splitting to  improve  performance  by  processing
              multiple  concurrent  mini-batches. The default value for Split-
              Type is None , which indicates that input  data  files  are  not
              split,  and  request  payloads contain the entire contents of an
              input object. Set the value of this parameter to Line  to  split
              records on a newline character boundary. SplitType also supports
              a number of record-oriented binary data formats. Currently,  the
              supported record formats are:

              o RecordIO

              o TFRecord

              When  splitting  is enabled, the size of a mini-batch depends on
              the values of the BatchStrategy and  MaxPayloadInMB  parameters.
              When  the  value  of BatchStrategy is MultiRecord , Amazon Sage-
              Maker sends the maximum number of records in each request, up to
              the  MaxPayloadInMB limit. If the value of BatchStrategy is Sin-
              gleRecord , Amazon SageMaker sends individual  records  in  each
              request.

              NOTE:
                 Some  data  formats  represent  a  record as a binary payload
                 wrapped with extra padding bytes. When splitting  is  applied
                 to  a  binary data format, padding is removed if the value of
                 BatchStrategy is set to SingleRecord . Padding is not removed
                 if the value of BatchStrategy is set to MultiRecord .

                 For  more  information  about RecordIO , see Create a Dataset
                 Using RecordIO in the MXNet documentation. For more  informa-
                 tion about TFRecord , see Consuming TFRecord data in the Ten-
                 sorFlow documentation.

       Shorthand Syntax:

          DataSource={S3DataSource={S3DataType=string,S3Uri=string}},ContentType=string,CompressionType=string,SplitType=string

       JSON Syntax:

          {
            "DataSource": {
              "S3DataSource": {
                "S3DataType": "ManifestFile"|"S3Prefix"|"AugmentedManifestFile",
                "S3Uri": "string"
              }
            },
            "ContentType": "string",
            "CompressionType": "None"|"Gzip",
            "SplitType": "None"|"Line"|"RecordIO"|"TFRecord"
          }

       --transform-output (structure)
          Describes the results of the transform job.

          S3OutputPath -> (string)
              The Amazon S3 path where you want Amazon SageMaker to store  the
              results     of     the     transform     job.    For    example,
              s3://bucket-name/key-name-prefix .

              For every S3 object used as input for the transform  job,  batch
              transform stores the transformed data with an .``out`` suffix in
              a corresponding subfolder in the location in the output  prefix.
              For  example,  for the input data stored at s3://bucket-name/in-
              put-name-prefix/dataset01/data.csv , batch transform stores  the
              transformed   data   at  s3://bucket-name/output-name-prefix/in-
              put-name-prefix/data.csv.out . Batch  transform  doesn't  upload
              partially  processed  objects.  For an input S3 object that con-
              tains multiple records, it creates an .``out`` file only if  the
              transform  job  succeeds on the entire file. When the input con-
              tains multiple S3 objects, the batch transform job processes the
              listed  S3  objects and uploads only the output for successfully
              processed objects. If any object  fails  in  the  transform  job
              batch transform marks the job as failed to prompt investigation.

          Accept -> (string)
              The  MIME type used to specify the output data. Amazon SageMaker
              uses the MIME type with each http call to transfer data from the
              transform job.

          AssembleWith -> (string)
              Defines  how  to  assemble the results of the transform job as a
              single S3 object. Choose a format that  is  most  convenient  to
              you. To concatenate the results in binary format, specify None .
              To add a newline character  at  the  end  of  every  transformed
              record, specify Line .

          KmsKeyId -> (string)
              The  Amazon Web Services Key Management Service (Amazon Web Ser-
              vices KMS) key that Amazon SageMaker uses to encrypt  the  model
              artifacts  at  rest  using Amazon S3 server-side encryption. The
              KmsKeyId can be any of the following formats:

              o Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab

              o Key                                                       ARN:
                arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab

              o Alias name: alias/ExampleAlias

              o Alias name ARN: arn:aws:kms:us-west-2:111122223333:alias/Exam-
                pleAlias

              If you don't provide a KMS key ID, Amazon SageMaker uses the de-
              fault KMS key for Amazon S3 for your role's  account.  For  more
              information,  see KMS-Managed Encryption Keys in the Amazon Sim-
              ple Storage Service Developer Guide.

              The KMS key policy must grant permission to the  IAM  role  that
              you  specify  in your CreateModel request. For more information,
              see Using Key Policies in Amazon Web Services KMS in the  Amazon
              Web Services Key Management Service Developer Guide .

       Shorthand Syntax:

          S3OutputPath=string,Accept=string,AssembleWith=string,KmsKeyId=string

       JSON Syntax:

          {
            "S3OutputPath": "string",
            "Accept": "string",
            "AssembleWith": "None"|"Line",
            "KmsKeyId": "string"
          }

       --data-capture-config (structure)
          Configuration to control how SageMaker captures inference data.

          DestinationS3Uri -> (string)
              The Amazon S3 location being used to capture the data.

          KmsKeyId -> (string)
              The Amazon Resource Name (ARN) of a Amazon Web Services Key Man-
              agement Service key that SageMaker uses to encrypt data  on  the
              storage  volume  attached  to the ML compute instance that hosts
              the batch transform job.

              The KmsKeyId can be any of the following formats:

              o Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab

              o Key                                                       ARN:
                arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab

              o Alias name: alias/ExampleAlias

              o Alias name ARN: arn:aws:kms:us-west-2:111122223333:alias/Exam-
                pleAlias

          GenerateInferenceId -> (boolean)
              Flag  that  indicates whether to append inference id to the out-
              put.

       Shorthand Syntax:

          DestinationS3Uri=string,KmsKeyId=string,GenerateInferenceId=boolean

       JSON Syntax:

          {
            "DestinationS3Uri": "string",
            "KmsKeyId": "string",
            "GenerateInferenceId": true|false
          }

       --transform-resources (structure)
          Describes the resources, including ML instance types and ML instance
          count, to use for the transform job.

          InstanceType -> (string)
              The  ML  compute instance type for the transform job. If you are
              using  built-in  algorithms  to   transform   moderately   sized
              datasets,  we  recommend  using  ml.m4.xlarge or ml.m5.large in-
              stance types.

          InstanceCount -> (integer)
              The number of ML compute instances to use in the transform  job.
              The  default  value is 1 , and the maximum is 100 . For distrib-
              uted transform jobs, specify a value greater than 1 .

          VolumeKmsKeyId -> (string)
              The Amazon Web Services Key Management Service (Amazon Web  Ser-
              vices  KMS) key that Amazon SageMaker uses to encrypt model data
              on the storage volume attached to  the  ML  compute  instance(s)
              that run the batch transform job.

              NOTE:
                 Certain  Nitro-based  instances include local storage, depen-
                 dent on the instance type.  Local  storage  volumes  are  en-
                 crypted  using  a  hardware module on the instance. You can't
                 request a VolumeKmsKeyId when using an instance type with lo-
                 cal storage.

                 For  a  list  of  instance  types that support local instance
                 storage, see Instance Store Volumes .

                 For more information about local instance storage encryption,
                 see SSD Instance Store Volumes .

              The VolumeKmsKeyId can be any of the following formats:

              o Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab

              o Key                                                       ARN:
                arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab

              o Alias name: alias/ExampleAlias

              o Alias name ARN: arn:aws:kms:us-west-2:111122223333:alias/Exam-
                pleAlias

       Shorthand Syntax:

          InstanceType=string,InstanceCount=integer,VolumeKmsKeyId=string

       JSON Syntax:

          {
            "InstanceType": "ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.m6i.large"|"ml.m6i.xlarge"|"ml.m6i.2xlarge"|"ml.m6i.4xlarge"|"ml.m6i.8xlarge"|"ml.m6i.12xlarge"|"ml.m6i.16xlarge"|"ml.m6i.24xlarge"|"ml.m6i.32xlarge"|"ml.c6i.large"|"ml.c6i.xlarge"|"ml.c6i.2xlarge"|"ml.c6i.4xlarge"|"ml.c6i.8xlarge"|"ml.c6i.12xlarge"|"ml.c6i.16xlarge"|"ml.c6i.24xlarge"|"ml.c6i.32xlarge"|"ml.r6i.large"|"ml.r6i.xlarge"|"ml.r6i.2xlarge"|"ml.r6i.4xlarge"|"ml.r6i.8xlarge"|"ml.r6i.12xlarge"|"ml.r6i.16xlarge"|"ml.r6i.24xlarge"|"ml.r6i.32xlarge"|"ml.m7i.large"|"ml.m7i.xlarge"|"ml.m7i.2xlarge"|"ml.m7i.4xlarge"|"ml.m7i.8xlarge"|"ml.m7i.12xlarge"|"ml.m7i.16xlarge"|"ml.m7i.24xlarge"|"ml.m7i.48xlarge"|"ml.c7i.large"|"ml.c7i.xlarge"|"ml.c7i.2xlarge"|"ml.c7i.4xlarge"|"ml.c7i.8xlarge"|"ml.c7i.12xlarge"|"ml.c7i.16xlarge"|"ml.c7i.24xlarge"|"ml.c7i.48xlarge"|"ml.r7i.large"|"ml.r7i.xlarge"|"ml.r7i.2xlarge"|"ml.r7i.4xlarge"|"ml.r7i.8xlarge"|"ml.r7i.12xlarge"|"ml.r7i.16xlarge"|"ml.r7i.24xlarge"|"ml.r7i.48xlarge"|"ml.g4dn.xlarge"|"ml.g4dn.2xlarge"|"ml.g4dn.4xlarge"|"ml.g4dn.8xlarge"|"ml.g4dn.12xlarge"|"ml.g4dn.16xlarge"|"ml.g5.xlarge"|"ml.g5.2xlarge"|"ml.g5.4xlarge"|"ml.g5.8xlarge"|"ml.g5.12xlarge"|"ml.g5.16xlarge"|"ml.g5.24xlarge"|"ml.g5.48xlarge",
            "InstanceCount": integer,
            "VolumeKmsKeyId": "string"
          }

       --data-processing (structure)
          The data structure used to specify the data to be used for inference
          in  a batch transform job and to associate the data that is relevant
          to the prediction results in the output. The input  filter  provided
          allows you to exclude input data that is not needed for inference in
          a batch transform job. The output filter provided allows you to  in-
          clude  input  data  relevant  to interpreting the predictions in the
          output from the job. For more information, see Associate  Prediction
          Results with their Corresponding Input Records .

          InputFilter -> (string)
              A JSONPath expression used to select a portion of the input data
              to pass to the algorithm. Use the InputFilter parameter  to  ex-
              clude  fields, such as an ID column, from the input. If you want
              SageMaker to pass the entire input dataset to the algorithm, ac-
              cept the default value $ .

              Examples: "$" , "$[1:]" , "$.features"

          OutputFilter -> (string)
              A  JSONPath  expression  used  to select a portion of the joined
              dataset to save in the output file for a batch transform job. If
              you want SageMaker to store the entire input dataset in the out-
              put file, leave the default value, $ . If  you  specify  indexes
              that aren't within the dimension size of the joined dataset, you
              get an error.

              Examples: "$" , "$[0,5:]" , "$['id','SageMakerOutput']"

          JoinSource -> (string)
              Specifies the source of the data to join  with  the  transformed
              data. The valid values are None and Input . The default value is
              None , which specifies not to join the  input  with  the  trans-
              formed  data.  If  you  want the batch transform job to join the
              original input data with the transformed data, set JoinSource to
              Input  . You can specify OutputFilter as an additional filter to
              select a portion of the joined dataset and store it in the  out-
              put file.

              For  JSON  or JSONLines objects, such as a JSON array, SageMaker
              adds the transformed data to the input JSON object in an  attri-
              bute called SageMakerOutput . The joined result for JSON must be
              a key-value pair object. If the input is not  a  key-value  pair
              object, SageMaker creates a new JSON file. In the new JSON file,
              and the input data is stored under the  SageMakerInput  key  and
              the results are stored in SageMakerOutput .

              For CSV data, SageMaker takes each row as a JSON array and joins
              the transformed data with the input  by  appending  each  trans-
              formed  row  to  the  end  of the input. The joined data has the
              original input data followed by the  transformed  data  and  the
              output is a CSV file.

              For  information on how joining in applied, see Workflow for As-
              sociating Inferences with Input Records .

       Shorthand Syntax:

          InputFilter=string,OutputFilter=string,JoinSource=string

       JSON Syntax:

          {
            "InputFilter": "string",
            "OutputFilter": "string",
            "JoinSource": "Input"|"None"
          }

       --tags (list)
          (Optional) An array of key-value pairs. For  more  information,  see
          Using  Cost  Allocation  Tags in the Amazon Web Services Billing and
          Cost Management User Guide .

          (structure)
              A tag object that consists of a key and an optional value,  used
              to manage metadata for SageMaker Amazon Web Services resources.

              You  can add tags to notebook instances, training jobs, hyperpa-
              rameter tuning jobs,  batch  transform  jobs,  models,  labeling
              jobs,  work  teams,  endpoint configurations, and endpoints. For
              more information on adding  tags  to  SageMaker  resources,  see
              AddTags .

              For  more information on adding metadata to your Amazon Web Ser-
              vices resources with tagging, see Tagging  Amazon  Web  Services
              resources . For advice on best practices for managing Amazon Web
              Services resources with tagging, see Tagging Best Practices: Im-
              plement an Effective Amazon Web Services Resource Tagging Strat-
              egy .

              Key -> (string)
                 The tag key. Tag keys must be unique per resource.

              Value -> (string)
                 The tag value.

       Shorthand Syntax:

          Key=string,Value=string ...

       JSON Syntax:

          [
            {
              "Key": "string",
              "Value": "string"
            }
            ...
          ]

       --experiment-config (structure)
          Associates a SageMaker job as a trial component with  an  experiment
          and trial. Specified when you call the following APIs:

          o CreateProcessingJob

          o CreateTrainingJob

          o CreateTransformJob

          ExperimentName -> (string)
              The  name  of an existing experiment to associate with the trial
              component.

          TrialName -> (string)
              The name of an existing trial to associate the  trial  component
              with. If not specified, a new trial is created.

          TrialComponentDisplayName -> (string)
              The  display  name  for  the  trial component. If this key isn't
              specified, the display name is the trial component name.

          RunName -> (string)
              The name of the experiment run to associate with the trial  com-
              ponent.

       Shorthand Syntax:

          ExperimentName=string,TrialName=string,TrialComponentDisplayName=string,RunName=string

       JSON Syntax:

          {
            "ExperimentName": "string",
            "TrialName": "string",
            "TrialComponentDisplayName": "string",
            "RunName": "string"
          }

       --cli-input-json  (string) Performs service operation based on the JSON
       string provided. The JSON string follows the format provided by  --gen-
       erate-cli-skeleton.  If  other  arguments  are  provided on the command
       line, the CLI values will override the JSON-provided values. It is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for  --cli-input-json.  If provided with the value output, it validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By default, the AWS CLI uses SSL when communicating with AWS  services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do not sign requests. Credentials will not be loaded if  this  argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The maximum socket read time in seconds. If the value is set to 0,  the
       socket  read  will be blocking and not timeout. The default value is 60
       seconds.

       --cli-connect-timeout (int)

       The maximum socket connect time in seconds. If the value is set  to  0,
       the  socket connect will be blocking and not timeout. The default value
       is 60 seconds.

OUTPUT
       TransformJobArn -> (string)
          The Amazon Resource Name (ARN) of the transform job.



                                                        CREATE-TRANSFORM-JOB()
