UPDATE-MODEL-PACKAGE()                                  UPDATE-MODEL-PACKAGE()



NAME
       update-model-package -

DESCRIPTION
       Updates a versioned model.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            update-model-package
          --model-package-arn <value>
          [--model-approval-status <value>]
          [--approval-description <value>]
          [--customer-metadata-properties <value>]
          [--customer-metadata-properties-to-remove <value>]
          [--additional-inference-specifications-to-add <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --model-package-arn (string)
          The Amazon Resource Name (ARN) of the model package.

       --model-approval-status (string)
          The approval status of the model.

          Possible values:

          o Approved

          o Rejected

          o PendingManualApproval

       --approval-description (string)
          A description for the approval status of the model.

       --customer-metadata-properties (map)
          The metadata properties associated with the model package versions.

          key -> (string)

          value -> (string)

       Shorthand Syntax:

          KeyName1=string,KeyName2=string

       JSON Syntax:

          {"string": "string"
            ...}

       --customer-metadata-properties-to-remove (list)
          The  metadata  properties associated with the model package versions
          to remove.

          (string)

       Syntax:

          "string" "string" ...

       --additional-inference-specifications-to-add (list)
          An array of additional Inference Specification objects to  be  added
          to the existing array additional Inference Specification. Total num-
          ber of additional Inference Specifications can not exceed  15.  Each
          additional Inference Specification specifies artifacts based on this
          model package that can be used  on  inference  endpoints.  Generally
          used with SageMaker Neo to store the compiled artifacts.

          (structure)
              A  structure  of  additional Inference Specification. Additional
              Inference Specification specifies details about  inference  jobs
              that can be run with models based on this model package

              Name -> (string)
                 A unique name to identify the additional inference specifica-
                 tion. The name must be unique within the list of  your  addi-
                 tional  inference specifications for a particular model pack-
                 age.

              Description -> (string)
                 A description of the additional Inference specification

              Containers -> (list)
                 The Amazon ECR registry path of the Docker  image  that  con-
                 tains the inference code.

                 (structure)
                     Describes the Docker container for the model package.

                     ContainerHostname -> (string)
                        The DNS host name for the Docker container.

                     Image -> (string)
                        The  Amazon  EC2  Container Registry (Amazon ECR) path
                        where inference code is stored.

                        If you are using your own custom algorithm instead  of
                        an  algorithm provided by Amazon SageMaker, the infer-
                        ence code must  meet  Amazon  SageMaker  requirements.
                        Amazon   SageMaker   supports   both  registry/reposi-
                        tory[:tag] and registry/repository[@digest] image path
                        formats.  For more information, see Using Your Own Al-
                        gorithms with Amazon SageMaker .

                     ImageDigest -> (string)
                        An MD5 hash of the training algorithm that  identifies
                        the Docker image used for training.

                     ModelDataUrl -> (string)
                        The  Amazon  S3  path where the model artifacts, which
                        result from model training, are stored. This path must
                        point to a single gzip compressed tar archive (.tar.gz
                        suffix).

                        NOTE:
                            The model artifacts must be in an S3  bucket  that
                            is in the same region as the model package.

                     ProductId -> (string)
                        The  Amazon Web Services Marketplace product ID of the
                        model package.

                     Environment -> (map)
                        The environment variables to set in  the  Docker  con-
                        tainer.  Each  key and value in the Environment string
                        to string map can have length of up to 1024.  We  sup-
                        port up to 16 entries in the map.

                        key -> (string)

                        value -> (string)

                     ModelInput -> (structure)
                        A structure with Model Input details.

                        DataInputConfig -> (string)
                            The input configuration object for the model.

                     Framework -> (string)
                        The  machine  learning  framework of the model package
                        container image.

                     FrameworkVersion -> (string)
                        The framework version of the Model  Package  Container
                        Image.

                     NearestModelName -> (string)
                        The name of a pre-trained machine learning benchmarked
                        by Amazon SageMaker Inference Recommender  model  that
                        matches your model. You can find a list of benchmarked
                        models by calling ListModelMetadata .

              SupportedTransformInstanceTypes -> (list)
                 A list of the instance types on which  a  transformation  job
                 can be run or on which an endpoint can be deployed.

                 (string)

              SupportedRealtimeInferenceInstanceTypes -> (list)
                 A list of the instance types that are used to generate infer-
                 ences in real-time.

                 (string)

              SupportedContentTypes -> (list)
                 The supported MIME types for the input data.

                 (string)

              SupportedResponseMIMETypes -> (list)
                 The supported MIME types for the output data.

                 (string)

       JSON Syntax:

          [
            {
              "Name": "string",
              "Description": "string",
              "Containers": [
                {
                  "ContainerHostname": "string",
                  "Image": "string",
                  "ImageDigest": "string",
                  "ModelDataUrl": "string",
                  "ProductId": "string",
                  "Environment": {"string": "string"
                    ...},
                  "ModelInput": {
                    "DataInputConfig": "string"
                  },
                  "Framework": "string",
                  "FrameworkVersion": "string",
                  "NearestModelName": "string"
                }
                ...
              ],
              "SupportedTransformInstanceTypes": ["ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.g4dn.xlarge"|"ml.g4dn.2xlarge"|"ml.g4dn.4xlarge"|"ml.g4dn.8xlarge"|"ml.g4dn.12xlarge"|"ml.g4dn.16xlarge", ...],
              "SupportedRealtimeInferenceInstanceTypes": ["ml.t2.medium"|"ml.t2.large"|"ml.t2.xlarge"|"ml.t2.2xlarge"|"ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.m5d.large"|"ml.m5d.xlarge"|"ml.m5d.2xlarge"|"ml.m5d.4xlarge"|"ml.m5d.12xlarge"|"ml.m5d.24xlarge"|"ml.c4.large"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.c5.large"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.c5d.large"|"ml.c5d.xlarge"|"ml.c5d.2xlarge"|"ml.c5d.4xlarge"|"ml.c5d.9xlarge"|"ml.c5d.18xlarge"|"ml.g4dn.xlarge"|"ml.g4dn.2xlarge"|"ml.g4dn.4xlarge"|"ml.g4dn.8xlarge"|"ml.g4dn.12xlarge"|"ml.g4dn.16xlarge"|"ml.r5.large"|"ml.r5.xlarge"|"ml.r5.2xlarge"|"ml.r5.4xlarge"|"ml.r5.12xlarge"|"ml.r5.24xlarge"|"ml.r5d.large"|"ml.r5d.xlarge"|"ml.r5d.2xlarge"|"ml.r5d.4xlarge"|"ml.r5d.12xlarge"|"ml.r5d.24xlarge"|"ml.inf1.xlarge"|"ml.inf1.2xlarge"|"ml.inf1.6xlarge"|"ml.inf1.24xlarge", ...],
              "SupportedContentTypes": ["string", ...],
              "SupportedResponseMIMETypes": ["string", ...]
            }
            ...
          ]

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       ModelPackageArn -> (string)
          The Amazon Resource Name (ARN) of the model.



                                                        UPDATE-MODEL-PACKAGE()
